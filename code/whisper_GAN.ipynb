{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5thx0SEBIIN"
   },
   "source": [
    "# Initialisation and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9rvOFi6QJP0z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc, math, traceback, datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import whisper\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import audio, training\n",
    "from utils.attacks import PrepareMethod, PrepareFront\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EjUegebBNcX"
   },
   "source": [
    "# GPU RAM Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jobgOLtEeLpx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cuda_usage(msg: str = \"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{msg}{torch.cuda.memory_allocated(0)/(1024 ** 3)} GB\")\n",
    "\n",
    "def get_cuda_usage():\n",
    "    return torch.cuda.memory_allocated(0)/(1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1zjyFx78LvD-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNEPbtquUG_g"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aTrPYXKiygaU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "    print(\"Model deleted!\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zfgWJdLVJRbS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"tiny.en\"\n",
    "\n",
    "model = whisper.load_model(MODEL_NAME).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tolbjGxG7qB8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model.is_multilingual, num_languages=model.num_languages, language=\"en\", task=\"transcribe\")\n",
    "sot_ids = torch.tensor(tokenizer.sot_sequence_including_notimestamps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8P5xS3UBTfT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "upnfsCvahcEJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tedlium_path = \"../tedlium\"\n",
    "train_path, validation_path, test_path = f\"{tedlium_path}/train_idx.hf\", f\"{tedlium_path}/validation_idx.hf\", f\"{tedlium_path}/test.hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e621843e6e084f00ae59a80060daee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_SELECT = 500\n",
    "VALID_SELECT = 150\n",
    "TEST_SELECT = 250\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "tedlium_train = load_from_disk(train_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TRAIN_SELECT))\n",
    "tedlium_validation = load_from_disk(validation_path).with_format(\"torch\").shuffle(seed=SEED).select(range(VALID_SELECT))\n",
    "tedlium_test = load_from_disk(test_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TEST_SELECT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MoAt_Utrb4sT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(ls):\n",
    "    pad_to = max(list(map(lambda x: x[\"audio\"].shape[0], ls)))\n",
    "    return torch.cat(list(map(lambda x: F.pad(x[\"audio\"], (0, pad_to - x[\"audio\"].shape[0])).unsqueeze(0).to(torch.bfloat16), ls)), dim=0)\n",
    "\n",
    "def collate_idx(ls):\n",
    "    return ls[0][\"audio\"].unsqueeze(0), ls[0][\"idx\"].item()\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1 # highly recommended to be 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = DataLoader(tedlium_train, batch_size=TRAIN_BATCH_SIZE, collate_fn=collate_idx)\n",
    "validation_dataset = DataLoader(tedlium_validation, batch_size=VALID_BATCH_SIZE, collate_fn=collate_idx)\n",
    "test_dataset = DataLoader(tedlium_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEl7cH9fBbZb"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lejmrAxFOy5E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_autograd_more(model: whisper.model.Whisper,\n",
    "                      train_data: torch.utils.data.DataLoader, valid_data: torch.utils.data.DataLoader,\n",
    "                      prepare_method: PrepareMethod,\n",
    "                      writer: Optional[SummaryWriter] = None,\n",
    "                      train_success: Optional[dict] = None, valid_success: Optional[dict] = None,\n",
    "                      lr: float = 1e-3,\n",
    "                      iter_limit: Optional[int] = None, mins_limit: Optional[int] = None, patience: Optional[int] = None, clamp_epsilon: Optional[float] = None\n",
    "                          ) -> torch.Tensor:\n",
    "    \n",
    "    # initialise stuff\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "    loss = torch.tensor(np.inf, requires_grad=True)\n",
    "    num_training_batches = len(train_data)\n",
    "    num_valid_batches = len(valid_data)\n",
    "\n",
    "    time_limit = mins_limit * 60 if mins_limit else None\n",
    "\n",
    "    snippet = torch.rand(prepare_method.snippet_size, requires_grad=True, device=device) # adversarial snippet\n",
    "    \n",
    "    snippets = [snippet]\n",
    "    buffer = None\n",
    "\n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            snippet = snippet * clamp_epsilon\n",
    "    snippet.requires_grad = True\n",
    "\n",
    "    optim = torch.optim.AdamW([snippet], lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.5)\n",
    "\n",
    "    attack_stack, attacked_data, mel, logits, pbar, avg_valid_loss = None, None, None, None, None, None\n",
    "    lowest_valid_loss = np.inf\n",
    "    curr_patience = patience\n",
    "    best_snippet = snippet.detach().clone()\n",
    "\n",
    "    # display attack method and snippet for sanity check\n",
    "    print(f\"Prepare method: {prepare_method.name}\")\n",
    "    print(f\"Snippet initialised to [{torch.min(snippet)}, {torch.max(snippet)}] of size {prepare_method.snippet_size}\")\n",
    "    print(f\"Clamp: {clamp_epsilon}\\nTime Limit (Mins): {mins_limit}\\nEpochs Limit: {iter_limit}\")\n",
    "    print(f\"Tracking training success: {train_success is not None}\\nTracking valid success: {valid_success is not None}\")\n",
    "\n",
    "    # log attack snippet\n",
    "    if writer:\n",
    "        writer.add_image(\"Attack Snippet\", audio.mel_image(snippet.detach().to(\"cpu\")), 0, dataformats=\"HWC\")\n",
    "        writer.flush()\n",
    "\n",
    "    # progress bar\n",
    "    pbar = tqdm(range(1), desc=\"Training\", ncols=0)\n",
    "    itera = 0\n",
    "\n",
    "    # track gpu usage\n",
    "    base_cuda_usage = get_cuda_usage()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = torch.zeros((len(train_data), 1))\n",
    "            itera += 1\n",
    "            if iter_limit:\n",
    "                iter_limit -= 1\n",
    "                if iter_limit <= 0:\n",
    "                    pbar.set_postfix_str(\"Epoch limit reached! Terminating...\")\n",
    "                    break\n",
    "            if time_limit and pbar.format_dict[\"elapsed\"] >= time_limit:\n",
    "                pbar.set_postfix_str(\"Time limit reached! Terminating...\")\n",
    "                break\n",
    "            if patience and avg_valid_loss:\n",
    "                if curr_patience <= 0:\n",
    "                    pbar.set_postfix_str(\"Patience expired! Terminating...\")\n",
    "                    break\n",
    "            if clamp_epsilon and audio.violates_clamp(snippet, clamp_epsilon):\n",
    "                raise ValueError(\"Snippet values violate clamp constraint!!\")\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_valid_loss = 0\n",
    "            total_cuda_usage_iter = 0\n",
    "\n",
    "            for batch_no, (batch, idx) in enumerate(train_data):\n",
    "                pbar.set_postfix_str(f\"Iter {itera}, Training Batch {batch_no + 1}/{num_training_batches}\")\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                attacked_data = prepare_method(snippet, batch)\n",
    "\n",
    "                # forward prop\n",
    "                mel = training.audio_to_mel_batch(attacked_data)\n",
    "                logits = training.mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                loss = training.get_loss_batch(logits, tokenizer.eot)\n",
    "                \n",
    "                # get training metrics\n",
    "                total_cuda_usage_iter += get_cuda_usage()\n",
    "                avg_training_loss += loss.detach()\n",
    "\n",
    "                # backprop\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                # clamp snippet\n",
    "                if clamp_epsilon:\n",
    "                    with torch.no_grad():\n",
    "                        snippet.clamp_(min=-clamp_epsilon, max=clamp_epsilon)\n",
    "                        \n",
    "                snippet.requires_grad = True\n",
    "                batch.to(\"cpu\")\n",
    "                \n",
    "                if train_success:\n",
    "                    with torch.no_grad():\n",
    "                        seq_length = len(model.transcribe(attacked_data.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                        train_success[idx] = train_success.get(idx, []) + [seq_length]\n",
    "            \n",
    "            snippets.append(snippet.detach().clone())\n",
    "            avg_training_loss /= len(train_data)\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                for batch_no, (v, idx) in enumerate(valid_data):\n",
    "                    pbar.set_postfix_str(f\"Iter {itera}, Validation Batch {batch_no + 1}/{num_valid_batches}\")\n",
    "                    v = v.to(device)\n",
    "                    attacked_data_valid = prepare_method(snippet, v)\n",
    "                    mel_valid = training.audio_to_mel_batch(attacked_data_valid)\n",
    "                    logits_valid = training.mel_to_logits_batch(model, mel_valid, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                    avg_valid_loss += training.get_loss_batch(logits_valid, tokenizer.eot)\n",
    "                    \n",
    "                    if valid_success:\n",
    "                        seq_length = len(model.transcribe(attacked_data_valid.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                        valid_success[idx] = valid_success.get(idx, []) + [seq_length] \n",
    "            avg_valid_loss /= num_valid_batches\n",
    "            \n",
    "            # track lowest valid loss and save the snippet with lowest valid loss\n",
    "            if avg_valid_loss >= lowest_valid_loss:\n",
    "                curr_patience -= 1\n",
    "            else:\n",
    "                curr_patience = patience\n",
    "                lowest_valid_loss = avg_valid_loss\n",
    "                best_snippet = snippet.detach().clone()\n",
    "\n",
    "            pbar.write(f\"Trng Avg Loss: {avg_training_loss} | Valid Avg Loss: {avg_valid_loss} | Patience: {curr_patience} | LR: {scheduler.get_last_lr()} | Epoch Limit: {iter_limit}\")\n",
    "\n",
    "            if writer:\n",
    "              # log training and validation losses\n",
    "                writer.add_scalar(\"Training average loss\", avg_training_loss, itera)\n",
    "                writer.add_scalar(\"Validation average loss\", avg_valid_loss, itera)\n",
    "\n",
    "                # log GPU RAM usage\n",
    "                if torch.cuda.is_available():\n",
    "                    writer.add_scalar(\"GPU RAM Usage\", total_cuda_usage_iter / num_training_batches - base_cuda_usage, itera)\n",
    "\n",
    "              # log attack snippet and flush\n",
    "                writer.add_image(\"Attack Snippet\", audio.mel_image(snippet.detach().to(\"cpu\")), itera, dataformats=\"HWC\")\n",
    "                writer.flush()\n",
    "            \n",
    "            # LR decay\n",
    "            scheduler.step()\n",
    "            \n",
    "            # refresh pbar to (hopefully) force update of progress bar\n",
    "            pbar.refresh()\n",
    "\n",
    "    except Exception as e:\n",
    "        # need to explicitly close pbar here so traceback can print error\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "            traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # close pbar to free stdout/stdsys (cant rmb which one)\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "\n",
    "        # clear tensors from GPU memory to\n",
    "        # prevent memory leak\n",
    "        if attacked_data is not None:\n",
    "            attacked_data.to(\"cpu\")\n",
    "            del attacked_data\n",
    "            print(\"Cleared attacked data\")\n",
    "\n",
    "        if attack_stack is not None:\n",
    "            attack_stack.to(\"cpu\")\n",
    "            del attack_stack\n",
    "            print(\"Cleared attack stack\")\n",
    "\n",
    "        if mel is not None:\n",
    "            mel.to(\"cpu\")\n",
    "            del mel\n",
    "            print(\"Cleared mel\")\n",
    "\n",
    "        if logits is not None:\n",
    "            logits.to(\"cpu\")\n",
    "            del logits\n",
    "            print(\"Cleared logits\")\n",
    "        \n",
    "        if buffer is not None:\n",
    "            buffer.to(\"cpu\")\n",
    "            del buffer\n",
    "            print(\"Cleared buffer\")\n",
    "\n",
    "        loss.to(\"cpu\")\n",
    "        del loss\n",
    "        print(\"Cleared loss\")\n",
    "\n",
    "        # empty GPU cache and garbage collect\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print_cuda_usage()\n",
    "        \n",
    "        return best_snippet.detach().to(\"cpu\"), snippets, train_success, valid_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JML5ybTKPMEu",
    "outputId": "f3650f0c-d671-4acf-ae9f-40bc0e620d18",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29839134216308594 GB\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "jTU811FhsXQn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "PATIENCE = 5\n",
    "MIN_LIMIT = 45\n",
    "ITER_LIMIT = 30\n",
    "CLAMP_EP = 0.005\n",
    "SNIPPET_SIZE = (1, 7_200)\n",
    "PREPARE_METHOD = PrepareFront(SNIPPET_SIZE)\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "timestamp = datetime.datetime.now().strftime(f'%Y%m%d-%H%M%S_size_{SNIPPET_SIZE}_{PREPARE_METHOD.name}')\n",
    "writer = SummaryWriter(log_dir=f\"../runs/size_tests/{timestamp}\", max_queue=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBzfVKNgHYp",
    "outputId": "80ab88a8-906c-4d44-a477-98b8717e3fc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare method: prepare_front\n",
      "Snippet initialised to [1.231307322768771e-07, 0.004999547265470028] of size (1, 7200)\n",
      "Clamp: 0.005\n",
      "Time Limit (Mins): 45\n",
      "Epochs Limit: 30\n",
      "Tracking training success: False\n",
      "Tracking valid success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [01:35<?, ?it/s, Iter 1, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 2.9611971378326416 | Valid Avg Loss: 4.960256576538086 | Patience: 5 | LR: [0.001] | Epoch Limit: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [02:58<?, ?it/s, Iter 2, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.674847960472107 | Valid Avg Loss: 2.7228689193725586 | Patience: 5 | LR: [0.001] | Epoch Limit: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [04:16<?, ?it/s, Iter 3, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.1693347692489624 | Valid Avg Loss: 0.8300468325614929 | Patience: 5 | LR: [0.001] | Epoch Limit: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [05:28<?, ?it/s, Iter 4, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.1022229194641113 | Valid Avg Loss: 2.211855411529541 | Patience: 4 | LR: [0.001] | Epoch Limit: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [06:44<?, ?it/s, Iter 5, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.0541924238204956 | Valid Avg Loss: 0.5133804082870483 | Patience: 5 | LR: [0.001] | Epoch Limit: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [07:58<?, ?it/s, Iter 6, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.5191997289657593 | Valid Avg Loss: 0.43815889954566956 | Patience: 5 | LR: [0.0005] | Epoch Limit: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [09:17<?, ?it/s, Iter 7, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.4454873204231262 | Valid Avg Loss: 0.42102473974227905 | Patience: 5 | LR: [0.0005] | Epoch Limit: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [10:35<?, ?it/s, Iter 8, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.29079487919807434 | Valid Avg Loss: 0.6389398574829102 | Patience: 4 | LR: [0.0005] | Epoch Limit: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [11:48<?, ?it/s, Iter 9, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.4486815631389618 | Valid Avg Loss: 0.4781892001628876 | Patience: 3 | LR: [0.0005] | Epoch Limit: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [12:59<?, ?it/s, Iter 11, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.3319949209690094 | Valid Avg Loss: 0.16054540872573853 | Patience: 5 | LR: [0.0005] | Epoch Limit: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [14:09<?, ?it/s, Iter 11, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.151224285364151 | Valid Avg Loss: 0.2987344563007355 | Patience: 4 | LR: [0.00025] | Epoch Limit: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [15:18<?, ?it/s, Iter 12, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.10946016758680344 | Valid Avg Loss: 0.18363621830940247 | Patience: 3 | LR: [0.00025] | Epoch Limit: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [16:30<?, ?it/s, Iter 14, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.03047693707048893 | Valid Avg Loss: 0.12660570442676544 | Patience: 5 | LR: [0.00025] | Epoch Limit: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [17:42<?, ?it/s, Iter 15, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.01460226345807314 | Valid Avg Loss: 0.1209484413266182 | Patience: 5 | LR: [0.00025] | Epoch Limit: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [18:53<?, ?it/s, Iter 16, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.014870605431497097 | Valid Avg Loss: 0.1033320501446724 | Patience: 5 | LR: [0.00025] | Epoch Limit: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [20:06<?, ?it/s, Iter 16, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.004946685861796141 | Valid Avg Loss: 0.050993457436561584 | Patience: 5 | LR: [0.000125] | Epoch Limit: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [21:32<?, ?it/s, Iter 17, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0030082324519753456 | Valid Avg Loss: 0.036837078630924225 | Patience: 5 | LR: [0.000125] | Epoch Limit: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [23:02<?, ?it/s, Iter 18, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0021123371552675962 | Valid Avg Loss: 0.0335499532520771 | Patience: 5 | LR: [0.000125] | Epoch Limit: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [24:12<?, ?it/s, Iter 20, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.001693269470706582 | Valid Avg Loss: 0.03344477340579033 | Patience: 5 | LR: [0.000125] | Epoch Limit: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [25:16<?, ?it/s, Iter 21, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.001320177922025323 | Valid Avg Loss: 0.031240787357091904 | Patience: 5 | LR: [0.000125] | Epoch Limit: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [26:26<?, ?it/s, Iter 21, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0010461951605975628 | Valid Avg Loss: 0.027861621230840683 | Patience: 5 | LR: [6.25e-05] | Epoch Limit: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [27:54<?, ?it/s, Iter 22, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0009489025687798858 | Valid Avg Loss: 0.02726159431040287 | Patience: 5 | LR: [6.25e-05] | Epoch Limit: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [29:08<?, ?it/s, Iter 24, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0008954820805229247 | Valid Avg Loss: 0.026811914518475533 | Patience: 5 | LR: [6.25e-05] | Epoch Limit: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [30:17<?, ?it/s, Iter 24, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.000846687878947705 | Valid Avg Loss: 0.024500088766217232 | Patience: 5 | LR: [6.25e-05] | Epoch Limit: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [31:27<?, ?it/s, Iter 26, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.000793305691331625 | Valid Avg Loss: 0.026545628905296326 | Patience: 4 | LR: [6.25e-05] | Epoch Limit: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [32:35<?, ?it/s, Iter 26, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0006457081180997193 | Valid Avg Loss: 0.02012266032397747 | Patience: 5 | LR: [3.125e-05] | Epoch Limit: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [33:44<?, ?it/s, Iter 27, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0005899847019463778 | Valid Avg Loss: 0.02090502716600895 | Patience: 4 | LR: [3.125e-05] | Epoch Limit: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [34:53<?, ?it/s, Iter 29, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0005628010258078575 | Valid Avg Loss: 0.01842709816992283 | Patience: 5 | LR: [3.125e-05] | Epoch Limit: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [36:02<?, ?it/s, Epoch limit reached! Terminating...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.000520650006365031 | Valid Avg Loss: 0.019622595980763435 | Patience: 4 | LR: [3.125e-05] | Epoch Limit: 1\n",
      "Cleared attacked data\n",
      "Cleared mel\n",
      "Cleared logits\n",
      "Cleared buffer\n",
      "Cleared loss\n",
      "0.30533409118652344 GB\n"
     ]
    }
   ],
   "source": [
    "best_snippet, snippets, _, _ = training_autograd_more(model, train_dataset, validation_dataset, \n",
    "                                                            PREPARE_METHOD,\n",
    "                                                            writer, lr=LR, \n",
    "                                                            train_success=None, valid_success=None,\n",
    "                                                            iter_limit=ITER_LIMIT, mins_limit=MIN_LIMIT, patience=PATIENCE, clamp_epsilon=CLAMP_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "q59EbCsIfr-9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio.view_mel(best_snippet.detach().to(\"cpu\").squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-kaeGzDCEUV"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "uYCZCjkitb0J",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clamp: 0.005\n",
      "Prepare Method: prepare_front\n",
      "Snippet Size: (1, 7200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|| 250/250 [00:33<00:00,  7.55it/s, Valid Examples: 194 | Empty Sequences: 194 | Total SL = 0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total valid examples: 194\n",
      "Success rate (Empty): 1.0\n",
      "Success rate (ASL): 0.0 (attacked) out of 122.16494845360825 (original)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "# for now, metric is whether the transcription is empty or consists only of blank tokens\n",
    "\n",
    "def evaluate(snippet, prepare_method, model, test_dataset):\n",
    "    print(f\"Clamp: {CLAMP_EP}\\nPrepare Method: {prepare_method.name}\\nSnippet Size: {SNIPPET_SIZE}\")\n",
    "    empty_counter = 0\n",
    "    char_counter = 0\n",
    "    total_examples = 0\n",
    "    original_chars = 0\n",
    "\n",
    "    snippet = snippet.to(device)\n",
    "    pbar = tqdm(range(len(test_dataset)), desc=\"Inference\")\n",
    "    test_dataset_iter = iter(test_dataset)\n",
    "    model.eval()\n",
    "\n",
    "    for i in pbar:\n",
    "        # evaluate if there are any words at all\n",
    "        example, answer = next(test_dataset_iter).values()\n",
    "        if isinstance(answer, tuple) or isinstance(answer, list):\n",
    "            answer = answer[0]\n",
    "        if answer != \"ignore_time_segment_in_scoring\":\n",
    "            attacked_example = prepare_method(snippet, example.to(device))\n",
    "            transcription = model.transcribe(attacked_example.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"]\n",
    "\n",
    "            if not transcription.strip():\n",
    "                empty_counter += 1\n",
    "            char_counter += len(transcription.strip())\n",
    "            original_chars += len(answer)\n",
    "            total_examples += 1\n",
    "            pbar.set_postfix_str(f\"Valid Examples: {total_examples} | Empty Sequences: {empty_counter} | Total SL = {char_counter}\")\n",
    "\n",
    "        example.to(\"cpu\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"\\n\")\n",
    "    print(f\"Total valid examples: {total_examples}\")\n",
    "    print(f\"Success rate (Empty): {empty_counter/total_examples}\")\n",
    "    print(f\"Success rate (ASL): {char_counter/total_examples} (attacked) out of {original_chars/total_examples} (original)\")\n",
    "\n",
    "evaluate(best_snippet, PREPARE_METHOD, model, test_dataset) # commented to prevent the runtime from autorunning and crashing the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snippets = torch.stack(list(map(lambda x: x.cpu(), snippets)) + [best_snippet.cpu()])\n",
    "snippets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(snippets.squeeze(), \"snippets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, train_success.values()))), \"train_success.pt\")\n",
    "torch.save(torch.tensor(list(train_success.keys())), \"train_ids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, valid_success.values()))), \"valid_success.pt\")\n",
    "torch.save(torch.tensor(list(valid_success.keys())), \"valid_ids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hVIWKQO1V22"
   },
   "source": [
    "# Save and Hear Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise(random_snippet, ep):\n",
    "    # we assume torch.rand inits to [0, 1)\n",
    "    res = random_snippet * ep * 2 - ep\n",
    "    print(f\"Normalised, Min {torch.min(res)}, Max {torch.max(res)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD8MUV-y1Rsj"
   },
   "outputs": [],
   "source": [
    "# Save snippet to wav file\n",
    "save_audio(snippet, f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_snippet_only.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTI3OCNw5681"
   },
   "outputs": [],
   "source": [
    "save_audio(PREPARE_METHOD(snippet.to(\"cpu\"), tedlium_test[2][\"audio\"].unsqueeze(0)), f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_combined.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
