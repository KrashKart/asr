{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5thx0SEBIIN"
   },
   "source": [
    "# Initialisation and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9rvOFi6QJP0z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc, math, traceback, datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import whisper\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import audio, training\n",
    "from utils.attacks import PrepareMethod, PrepareFront\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EjUegebBNcX"
   },
   "source": [
    "# GPU RAM Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jobgOLtEeLpx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cuda_usage(msg: str = \"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{msg}{torch.cuda.memory_allocated(0)/(1024 ** 3)} GB\")\n",
    "\n",
    "def get_cuda_usage():\n",
    "    return torch.cuda.memory_allocated(0)/(1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1zjyFx78LvD-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNEPbtquUG_g"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aTrPYXKiygaU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "    print(\"Model deleted!\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zfgWJdLVJRbS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"tiny.en\"\n",
    "\n",
    "model = whisper.load_model(MODEL_NAME).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tolbjGxG7qB8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model.is_multilingual, num_languages=model.num_languages, language=\"en\", task=\"transcribe\")\n",
    "sot_ids = torch.tensor(tokenizer.sot_sequence_including_notimestamps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8P5xS3UBTfT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "upnfsCvahcEJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tedlium_path = \"../tedlium\"\n",
    "train_path, validation_path, test_path = f\"{tedlium_path}/train_idx.hf\", f\"{tedlium_path}/validation_idx.hf\", f\"{tedlium_path}/test.hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e621843e6e084f00ae59a80060daee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_SELECT = 500\n",
    "VALID_SELECT = 150\n",
    "TEST_SELECT = 250\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "tedlium_train = load_from_disk(train_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TRAIN_SELECT))\n",
    "tedlium_validation = load_from_disk(validation_path).with_format(\"torch\").shuffle(seed=SEED).select(range(VALID_SELECT))\n",
    "tedlium_test = load_from_disk(test_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TEST_SELECT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MoAt_Utrb4sT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(ls):\n",
    "    pad_to = max(list(map(lambda x: x[\"audio\"].shape[0], ls)))\n",
    "    return torch.cat(list(map(lambda x: F.pad(x[\"audio\"], (0, pad_to - x[\"audio\"].shape[0])).unsqueeze(0).to(torch.bfloat16), ls)), dim=0)\n",
    "\n",
    "def collate_idx(ls):\n",
    "    return ls[0][\"audio\"].unsqueeze(0), ls[0][\"idx\"].item()\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1 # highly recommended to be 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = DataLoader(tedlium_train, batch_size=TRAIN_BATCH_SIZE, collate_fn=collate_idx)\n",
    "validation_dataset = DataLoader(tedlium_validation, batch_size=VALID_BATCH_SIZE, collate_fn=collate_idx)\n",
    "test_dataset = DataLoader(tedlium_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEl7cH9fBbZb"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lejmrAxFOy5E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_autograd_more(model: whisper.model.Whisper,\n",
    "                      train_data: torch.utils.data.DataLoader, valid_data: torch.utils.data.DataLoader,\n",
    "                      prepare_method: PrepareMethod,\n",
    "                      writer: Optional[SummaryWriter] = None,\n",
    "                      train_success: Optional[dict] = None, valid_success: Optional[dict] = None,\n",
    "                      lr: float = 1e-3,\n",
    "                      iter_limit: Optional[int] = None, mins_limit: Optional[int] = None, patience: Optional[int] = None, clamp_epsilon: Optional[float] = None\n",
    "                          ) -> torch.Tensor:\n",
    "    \n",
    "    # initialise stuff\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "    loss = torch.tensor(np.inf, requires_grad=True)\n",
    "    num_training_batches = len(train_data)\n",
    "    num_valid_batches = len(valid_data)\n",
    "\n",
    "    time_limit = mins_limit * 60 if mins_limit else None\n",
    "\n",
    "    snippet = torch.rand(prepare_method.snippet_size, requires_grad=True, device=device) # adversarial snippet\n",
    "    \n",
    "    snippets = [snippet]\n",
    "    buffer = None\n",
    "\n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            snippet = snippet * clamp_epsilon\n",
    "    snippet.requires_grad = True\n",
    "\n",
    "    optim = torch.optim.AdamW([snippet], lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.5)\n",
    "\n",
    "    attack_stack, attacked_data, mel, logits, pbar, avg_valid_loss = None, None, None, None, None, None\n",
    "    lowest_valid_loss = np.inf\n",
    "    curr_patience = patience\n",
    "    best_snippet = snippet.detach().clone()\n",
    "\n",
    "    # display attack method and snippet for sanity check\n",
    "    print(f\"Prepare method: {prepare_method.name}\")\n",
    "    print(f\"Snippet initialised to [{torch.min(snippet)}, {torch.max(snippet)}] of size {prepare_method.snippet_size}\")\n",
    "    print(f\"Clamp: {clamp_epsilon}\\nTime Limit (Mins): {mins_limit}\\nEpochs Limit: {iter_limit}\")\n",
    "    print(f\"Tracking training success: {train_success is not None}\\nTracking valid success: {valid_success is not None}\")\n",
    "\n",
    "    # log attack snippet\n",
    "    if writer:\n",
    "        writer.add_image(\"Attack Snippet\", audio.mel_image(snippet.detach().to(\"cpu\")), 0, dataformats=\"HWC\")\n",
    "        writer.flush()\n",
    "\n",
    "    # progress bar\n",
    "    pbar = tqdm(range(1), desc=\"Training\", ncols=0)\n",
    "    itera = 0\n",
    "\n",
    "    # track gpu usage\n",
    "    base_cuda_usage = get_cuda_usage()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = torch.zeros((len(train_data), 1))\n",
    "            itera += 1\n",
    "            if iter_limit:\n",
    "                iter_limit -= 1\n",
    "                if iter_limit <= 0:\n",
    "                    pbar.set_postfix_str(\"Epoch limit reached! Terminating...\")\n",
    "                    break\n",
    "            if time_limit and pbar.format_dict[\"elapsed\"] >= time_limit:\n",
    "                pbar.set_postfix_str(\"Time limit reached! Terminating...\")\n",
    "                break\n",
    "            if patience and avg_valid_loss:\n",
    "                if curr_patience <= 0:\n",
    "                    pbar.set_postfix_str(\"Patience expired! Terminating...\")\n",
    "                    break\n",
    "            if clamp_epsilon and audio.violates_clamp(snippet, clamp_epsilon):\n",
    "                raise ValueError(\"Snippet values violate clamp constraint!!\")\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_valid_loss = 0\n",
    "            total_cuda_usage_iter = 0\n",
    "\n",
    "            for batch_no, (batch, idx) in enumerate(train_data):\n",
    "                pbar.set_postfix_str(f\"Iter {itera}, Training Batch {batch_no + 1}/{num_training_batches}\")\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                attacked_data = prepare_method(snippet, batch)\n",
    "\n",
    "                # forward prop\n",
    "                mel = training.audio_to_mel_batch(attacked_data)\n",
    "                logits = training.mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                loss = training.get_loss_batch(logits, tokenizer.eot)\n",
    "                \n",
    "                # get training metrics\n",
    "                total_cuda_usage_iter += get_cuda_usage()\n",
    "                avg_training_loss += loss.detach()\n",
    "\n",
    "                # backprop\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                # clamp snippet\n",
    "                if clamp_epsilon:\n",
    "                    with torch.no_grad():\n",
    "                        snippet.clamp_(min=-clamp_epsilon, max=clamp_epsilon)\n",
    "                        \n",
    "                snippet.requires_grad = True\n",
    "                batch.to(\"cpu\")\n",
    "                \n",
    "                if train_success:\n",
    "                    with torch.no_grad():\n",
    "                        seq_length = len(model.transcribe(attacked_data.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                        train_success[idx] = train_success.get(idx, []) + [seq_length]\n",
    "            \n",
    "            snippets.append(snippet.detach().clone())\n",
    "            avg_training_loss /= len(train_data)\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                for batch_no, (v, idx) in enumerate(valid_data):\n",
    "                    pbar.set_postfix_str(f\"Iter {itera}, Validation Batch {batch_no + 1}/{num_valid_batches}\")\n",
    "                    v = v.to(device)\n",
    "                    attacked_data_valid = prepare_method(snippet, v)\n",
    "                    mel_valid = training.audio_to_mel_batch(attacked_data_valid)\n",
    "                    logits_valid = training.mel_to_logits_batch(model, mel_valid, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                    avg_valid_loss += training.get_loss_batch(logits_valid, tokenizer.eot)\n",
    "                    \n",
    "                    if valid_success:\n",
    "                        seq_length = len(model.transcribe(attacked_data_valid.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                        valid_success[idx] = valid_success.get(idx, []) + [seq_length] \n",
    "            avg_valid_loss /= num_valid_batches\n",
    "            \n",
    "            # track lowest valid loss and save the snippet with lowest valid loss\n",
    "            if avg_valid_loss >= lowest_valid_loss:\n",
    "                curr_patience -= 1\n",
    "            else:\n",
    "                curr_patience = patience\n",
    "                lowest_valid_loss = avg_valid_loss\n",
    "                best_snippet = snippet.detach().clone()\n",
    "\n",
    "            pbar.write(f\"Trng Avg Loss: {avg_training_loss} | Valid Avg Loss: {avg_valid_loss} | Patience: {curr_patience} | LR: {scheduler.get_last_lr()} | Epoch Limit: {iter_limit}\")\n",
    "\n",
    "            if writer:\n",
    "              # log training and validation losses\n",
    "                writer.add_scalar(\"Training average loss\", avg_training_loss, itera)\n",
    "                writer.add_scalar(\"Validation average loss\", avg_valid_loss, itera)\n",
    "\n",
    "                # log GPU RAM usage\n",
    "                if torch.cuda.is_available():\n",
    "                    writer.add_scalar(\"GPU RAM Usage\", total_cuda_usage_iter / num_training_batches - base_cuda_usage, itera)\n",
    "\n",
    "              # log attack snippet and flush\n",
    "                writer.add_image(\"Attack Snippet\", audio.mel_image(snippet.detach().to(\"cpu\")), itera, dataformats=\"HWC\")\n",
    "                writer.flush()\n",
    "            \n",
    "            # LR decay\n",
    "            scheduler.step()\n",
    "            \n",
    "            # refresh pbar to (hopefully) force update of progress bar\n",
    "            pbar.refresh()\n",
    "\n",
    "    except Exception as e:\n",
    "        # need to explicitly close pbar here so traceback can print error\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "            traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # close pbar to free stdout/stdsys (cant rmb which one)\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "\n",
    "        # clear tensors from GPU memory to\n",
    "        # prevent memory leak\n",
    "        if attacked_data is not None:\n",
    "            attacked_data.to(\"cpu\")\n",
    "            del attacked_data\n",
    "            print(\"Cleared attacked data\")\n",
    "\n",
    "        if attack_stack is not None:\n",
    "            attack_stack.to(\"cpu\")\n",
    "            del attack_stack\n",
    "            print(\"Cleared attack stack\")\n",
    "\n",
    "        if mel is not None:\n",
    "            mel.to(\"cpu\")\n",
    "            del mel\n",
    "            print(\"Cleared mel\")\n",
    "\n",
    "        if logits is not None:\n",
    "            logits.to(\"cpu\")\n",
    "            del logits\n",
    "            print(\"Cleared logits\")\n",
    "        \n",
    "        if buffer is not None:\n",
    "            buffer.to(\"cpu\")\n",
    "            del buffer\n",
    "            print(\"Cleared buffer\")\n",
    "\n",
    "        loss.to(\"cpu\")\n",
    "        del loss\n",
    "        print(\"Cleared loss\")\n",
    "\n",
    "        # empty GPU cache and garbage collect\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print_cuda_usage()\n",
    "        \n",
    "        return best_snippet.detach().to(\"cpu\"), snippets, train_success, valid_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JML5ybTKPMEu",
    "outputId": "f3650f0c-d671-4acf-ae9f-40bc0e620d18",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29839134216308594 GB\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jTU811FhsXQn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "PATIENCE = 5\n",
    "MIN_LIMIT = 45\n",
    "ITER_LIMIT = 30\n",
    "CLAMP_EP = 0.005\n",
    "SNIPPET_SIZE = (1, 16_000)\n",
    "PREPARE_METHOD = PrepareFront(SNIPPET_SIZE)\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "timestamp = datetime.datetime.now().strftime(f'%Y%m%d-%H%M%S_size_{SNIPPET_SIZE}_{PREPARE_METHOD.name}')\n",
    "writer = SummaryWriter(log_dir=f\"../runs/size_tests/{timestamp}\", max_queue=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBzfVKNgHYp",
    "outputId": "80ab88a8-906c-4d44-a477-98b8717e3fc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare method: prepare_front\n",
      "Snippet initialised to [4.062993639308843e-07, 0.004999249242246151] of size (1, 16000)\n",
      "Clamp: 0.005\n",
      "Time Limit (Mins): 45\n",
      "Epochs Limit: 30\n",
      "Tracking training success: False\n",
      "Tracking valid success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [02:06<?, ?it/s, Iter 2, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.0670406818389893 | Valid Avg Loss: 0.1593322604894638 | Patience: 5 | LR: [0.001] | Epoch Limit: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [03:23<?, ?it/s, Iter 2, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.21804054081439972 | Valid Avg Loss: 0.02108546905219555 | Patience: 5 | LR: [0.001] | Epoch Limit: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [04:40<?, ?it/s, Iter 3, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0009898894932121038 | Valid Avg Loss: 0.0051187314093112946 | Patience: 5 | LR: [0.001] | Epoch Limit: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [05:55<?, ?it/s, Iter 4, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0002719082694966346 | Valid Avg Loss: 0.0036524005699902773 | Patience: 5 | LR: [0.001] | Epoch Limit: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [07:10<?, ?it/s, Iter 5, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.00017528512398712337 | Valid Avg Loss: 0.0029390279669314623 | Patience: 5 | LR: [0.001] | Epoch Limit: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [08:21<?, ?it/s, Iter 6, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.00013205244613345712 | Valid Avg Loss: 0.0025873470585793257 | Patience: 5 | LR: [0.0005] | Epoch Limit: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [09:33<?, ?it/s, Iter 8, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.00011168777564307675 | Valid Avg Loss: 0.0024304736871272326 | Patience: 5 | LR: [0.0005] | Epoch Limit: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [10:45<?, ?it/s, Iter 8, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 9.418971603736281e-05 | Valid Avg Loss: 0.002240395173430443 | Patience: 5 | LR: [0.0005] | Epoch Limit: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [11:59<?, ?it/s, Iter 9, Validation Batch 150/150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 7.748714415356517e-05 | Valid Avg Loss: 0.0021440251730382442 | Patience: 5 | LR: [0.0005] | Epoch Limit: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [13:11<?, ?it/s, Iter 11, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 6.306647264864296e-05 | Valid Avg Loss: 0.0020993947982788086 | Patience: 5 | LR: [0.0005] | Epoch Limit: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [14:02<?, ?it/s, Iter 11, Training Batch 451/500]"
     ]
    }
   ],
   "source": [
    "best_snippet, snippets, _, _ = training_autograd_more(model, train_dataset, validation_dataset, \n",
    "                                                            PREPARE_METHOD,\n",
    "                                                            writer, lr=LR, \n",
    "                                                            train_success=None, valid_success=None,\n",
    "                                                            iter_limit=ITER_LIMIT, mins_limit=MIN_LIMIT, patience=PATIENCE, clamp_epsilon=CLAMP_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q59EbCsIfr-9",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view_mel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mview_mel\u001b[49m(best_snippet\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'view_mel' is not defined"
     ]
    }
   ],
   "source": [
    "view_mel(best_snippet.detach().to(\"cpu\").squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-kaeGzDCEUV"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYCZCjkitb0J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "# for now, metric is whether the transcription is empty or consists only of blank tokens\n",
    "\n",
    "def evaluate(snippet, prepare_method, model, test_dataset):\n",
    "    print(f\"Clamp: {CLAMP_EP}\\nPrepare Method: {prepare_method.name}\")\n",
    "    empty_counter = 0\n",
    "    char_counter = 0\n",
    "    total_examples = 0\n",
    "    original_chars = 0\n",
    "\n",
    "    snippet = snippet.to(device)\n",
    "    pbar = tqdm(range(len(test_dataset)), desc=\"Inference\")\n",
    "    test_dataset_iter = iter(test_dataset)\n",
    "    model.eval()\n",
    "\n",
    "    for i in pbar:\n",
    "        # evaluate if there are any words at all\n",
    "        example, answer = next(test_dataset_iter).values()\n",
    "        if isinstance(answer, tuple) or isinstance(answer, list):\n",
    "            answer = answer[0]\n",
    "        if answer != \"ignore_time_segment_in_scoring\":\n",
    "            attacked_example = prepare_method(snippet, example.to(device))\n",
    "            transcription = model.transcribe(attacked_example.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"]\n",
    "\n",
    "            if not transcription.strip():\n",
    "                empty_counter += 1\n",
    "            char_counter += len(transcription.strip())\n",
    "            original_chars += len(answer)\n",
    "            total_examples += 1\n",
    "            pbar.set_postfix_str(f\"Valid Examples: {total_examples} | Empty Sequences: {empty_counter} | Total SL = {char_counter}\")\n",
    "\n",
    "        example.to(\"cpu\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"\\n\")\n",
    "    print(f\"Total valid examples: {total_examples}\")\n",
    "    print(f\"Success rate (Empty): {empty_counter/total_examples}\")\n",
    "    print(f\"Success rate (ASL): {char_counter/total_examples} (attacked) out of {original_chars/total_examples} (original)\")\n",
    "\n",
    "evaluate(best_snippet, PREPARE_METHOD, model, test_dataset) # commented to prevent the runtime from autorunning and crashing the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snippets = torch.stack(list(map(lambda x: x.cpu(), snippets)) + [best_snippet.cpu()])\n",
    "snippets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(snippets.squeeze(), \"snippets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, train_success.values()))), \"train_success.pt\")\n",
    "torch.save(torch.tensor(list(train_success.keys())), \"train_ids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, valid_success.values()))), \"valid_success.pt\")\n",
    "torch.save(torch.tensor(list(valid_success.keys())), \"valid_ids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hVIWKQO1V22"
   },
   "source": [
    "# Save and Hear Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise(random_snippet, ep):\n",
    "    # we assume torch.rand inits to [0, 1)\n",
    "    res = random_snippet * ep * 2 - ep\n",
    "    print(f\"Normalised, Min {torch.min(res)}, Max {torch.max(res)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD8MUV-y1Rsj"
   },
   "outputs": [],
   "source": [
    "# Save snippet to wav file\n",
    "save_audio(snippet, f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_snippet_only.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTI3OCNw5681"
   },
   "outputs": [],
   "source": [
    "save_audio(PREPARE_METHOD(snippet.to(\"cpu\"), tedlium_test[2][\"audio\"].unsqueeze(0)), f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_combined.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
