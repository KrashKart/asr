{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2eddfce-5184-4e86-ac86-3c93d8cb49f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc0cc82-5f33-4b0d-b753-54d66be9f8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc, math, traceback, datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import whisper\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "\n",
    "from utils import audio, gradient, gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca944260-2c7b-4247-8205-a933b2500aeb",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cf9c78-3257-412b-bd0c-600b43f13621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7132413f2924dcfb2bda9ce3de605dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = load_from_disk(\"../tedlium/test.hf\").with_format(\"torch\").select(range(100))\n",
    "train = load_from_disk(\"../tedlium/train.hf\").with_format(\"torch\").select(range(100))\n",
    "\n",
    "# wave = test[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61b7a68-4911-43d8-a76f-00e06a4554ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = gpu.get_device()\n",
    "whisper.load_model\n",
    "model = whisper.load_model(\"small.en\").to(device)\n",
    "target_id, sot_ids = gradient._get_ids(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c56096-d0db-4bb7-bbcd-e342d1653669",
   "metadata": {},
   "source": [
    "# Model and Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3b337c-fbb0-4f4a-ad5e-31426a24afa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shakedrop_hooks(mode, uni_dist, b_dist):\n",
    "    assert mode in [\"fwd\", \"bwd\", \"test\"]\n",
    "    def hook(module, x, output):\n",
    "        x = x[0]\n",
    "        b_l = b_dist.sample()\n",
    "        alpha = uni_dist.sample()\n",
    "        beta = uni_dist.sample()\n",
    "        return output\n",
    "        if mode == \"fwd\":\n",
    "            return x + (b_l + alpha - b_l * alpha) * output\n",
    "        elif mode == \"bwd\":\n",
    "            return x + (b_l + beta - b_l * beta) * output\n",
    "        else:\n",
    "            return x + (b_dist.mean + uni_dist.mean - b_dist.mean * uni_dist.mean) * output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309c7a75-327f-4755-80a1-157a72bc9d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_hooks(model_limit, model_layers):\n",
    "    hooks = []\n",
    "    uni, b = torch.distributions.uniform.Uniform(0, 1), torch.distributions.bernoulli.Bernoulli(0.4)\n",
    "    for _ in range(model_limit):\n",
    "        temp_fwd, temp_bwd, temp_test = [], [], []\n",
    "        temp = {}\n",
    "        for _ in range(model_layers):\n",
    "            temp_fwd.append(shakedrop_hooks(\"fwd\", uni, b))\n",
    "            temp_bwd.append(shakedrop_hooks(\"bwd\", uni, b))\n",
    "            temp_test.append(shakedrop_hooks(\"test\", uni, b))\n",
    "        temp[\"fwd\"], temp[\"bwd\"], temp[\"test\"] = temp_fwd, temp_bwd, temp_test\n",
    "        hooks.append(temp)\n",
    "    return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df75fa04-b6a1-45ab-9d95-4e048633ae40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_LIMIT = 10\n",
    "MODEL_LAYERS = len(model.encoder.blocks + model.decoder.blocks)\n",
    "\n",
    "hooks = generate_hooks(MODEL_LIMIT, MODEL_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b19c400-492b-4a86-870c-b0d00d80b24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(adv_audio, delta, data_limit):\n",
    "    result = []\n",
    "    for _ in range(data_limit):\n",
    "        result.append(adv_audio + torch.randn(adv_audio.shape).to(adv_audio.device) * delta)\n",
    "    return torch.stack(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e244d399-d804-48e4-b28d-ad45372edd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_LIMIT = 10\n",
    "DELTA = 0.05\n",
    "\n",
    "# data = generate_data(wave, DELTA, DATA_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1081f60-a0a3-4b0c-b1c2-ff07b61b2337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b714beb-6969-48ad-a9aa-338deb5b1776",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0c0d91-166d-4d74-8024-4b7506acfca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(model: whisper.model.Whisper, audio, sot_ids, target_id: int):\n",
    "    audio = audio.to(model.device)\n",
    "    mel = gradient.audio_to_mel_batch(audio)\n",
    "    logits = mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "    loss = gradient.get_loss_batch(logits, target_id)\n",
    "    return loss\n",
    "\n",
    "def mel_to_logits_batch(model: whisper.model.Whisper, mel_batch, sot_ids):\n",
    "    sot_ids = sot_ids.unsqueeze(0).expand(mel_batch.size(0), -1).to(model.device)\n",
    "    return model.forward(mel_batch, sot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717e1da7-7346-4be1-befa-5c2783caf35c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def register_hooks_on_model(model, hooks, mode):\n",
    "    assert mode in [\"fwd\", \"bwd\", \"test\"]\n",
    "    handles = []\n",
    "    layers = model.encoder.blocks + model.decoder.blocks\n",
    "    for i, h in enumerate(hooks[mode]):\n",
    "        if mode == \"bwd\":\n",
    "            han = layers[i].register_backward_hook(h)\n",
    "        else:\n",
    "            han = layers[i].register_forward_hook(h)\n",
    "        handles.append(han)\n",
    "    return handles\n",
    "\n",
    "def unregister_hooks_on_model(handles):\n",
    "    for h in handles:\n",
    "        h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2b11f0-6b9a-4371-af70-34f8e9442a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import traceback\n",
    "\n",
    "def loop(model, adv_audio, train_dataset, hooks, sot_ids, target_id, iters, mu, grad_mask, clamp_epsilon, lr):\n",
    "    try:\n",
    "        g_t = 0.0\n",
    "        g_st = g_wt = None\n",
    "        loss = white_box_loss = None\n",
    "        adv_audio = adv_audio.to(model.device)\n",
    "        benchmark_example = train[0][\"audio\"].to(model.device).unsqueeze(0)\n",
    "        fwd_handles = bwd_handles = None\n",
    "        pbar = tqdm.tqdm(range(iters), leave=True, ncols=0)\n",
    "        for i in pbar:\n",
    "            if i != 0 and i % 5 == 0:\n",
    "                lr *= 0.75\n",
    "            g_st = iter_loss = 0.0\n",
    "\n",
    "            pbar.set_postfix_str(\"Calculating white box loss\")\n",
    "            adv_audio.requires_grad = True\n",
    "            white_box_loss = forward(model, torch.cat([adv_audio, benchmark_example], dim=1), sot_ids, target_id)\n",
    "            white_box_loss.backward()\n",
    "            g_wt = adv_audio.grad.to(model.device)\n",
    "            adv_audio.requires_grad = False\n",
    "\n",
    "            pbar.set_postfix_str(\"Generating data\")\n",
    "            data = generate_data(adv_audio, DELTA, DATA_LIMIT).squeeze().detach()\n",
    "            dataset = DataLoader(data, batch_size=1)\n",
    "            \n",
    "            for data_idx, d in enumerate(dataset):\n",
    "                d = d.to(model.device)\n",
    "                d.requires_grad = True\n",
    "                \n",
    "                for model_idx, m in enumerate(hooks):                                     \n",
    "                    for batch_idx, b in enumerate(train_dataset):\n",
    "                        pbar.set_postfix_str(f\"Current: Data {data_idx + 1}/{len(dataset)} | Model {model_idx + 1}/{len(hooks)} | Train Batch {batch_idx + 1}/{len(train_dataset)}\")\n",
    "                        fwd_handles = register_hooks_on_model(model, m, \"fwd\")\n",
    "                        b = b.to(model.device)\n",
    "                        d_stacked = d.repeat(b.size(0), 1)\n",
    "                        loss = forward(model, torch.cat([d_stacked, b], dim=1), sot_ids, target_id)\n",
    "                        iter_loss += loss.detach().cpu().item()\n",
    "                        unregister_hooks_on_model(fwd_handles)\n",
    "\n",
    "                        bwd_handles = register_hooks_on_model(model, m, \"bwd\")\n",
    "                        loss.backward()\n",
    "                        unregister_hooks_on_model(bwd_handles)\n",
    "\n",
    "                        g_st += torch.sum(d.grad, dim=0)\n",
    "\n",
    "                d.requires_grad = False\n",
    "                d.cpu()\n",
    "\n",
    "            pbar.set_postfix_str(\"Updating adv_data\")\n",
    "            g_st *= 1 / (MODEL_LIMIT * DATA_LIMIT)\n",
    "            mask = (torch.rand(g_wt.shape) < grad_mask).float().to(model.device)\n",
    "            g_t = mu * g_t + (mask * g_wt + g_st) / torch.abs(mask * g_wt + g_st)\n",
    "            sign = torch.where(g_t > 0, 1, -1).to(device)\n",
    "            adv_audio = (adv_audio - lr * sign).clamp(min=-clamp_epsilon, max=clamp_epsilon)\n",
    "            \n",
    "            pbar.write(f\"White box loss: {white_box_loss} | Iteration loss: {iter_loss / (len(hooks) * len(dataset) * len(train_dataset))}\")\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if fwd_handles:\n",
    "            unregister_hooks_on_model(fwd_handles)\n",
    "            fwd_handles.clear()\n",
    "        if bwd_handles:\n",
    "            unregister_hooks_on_model(bwd_handles)\n",
    "            bwd_handles.clear()\n",
    "        if loss:\n",
    "            del loss\n",
    "        if white_box_loss is not None:\n",
    "            del white_box_loss\n",
    "        if g_st is not None:\n",
    "            del g_st\n",
    "        if g_wt is not None:\n",
    "            del g_wt\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        gpu.print_cuda_usage()\n",
    "        return adv_audio.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bc231d-449c-49f1-84e3-cef427860168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snippet = torch.rand((1, 4800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d766497-8475-463f-a3a2-d597e7a31e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "def collate(ls):\n",
    "    return ls[0][\"audio\"].unsqueeze(0)\n",
    "test_dataset = DataLoader(test)\n",
    "train_dataset = DataLoader(train, batch_size=20, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e95307d-695e-4ab5-bc18-9cfef4a2de59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.attacks import PrepareFront\n",
    "# gradient.evaluate(model, snippet, PrepareFront((1, 1600)), dataset, 0.005, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c955d7f3-febc-4782-98f7-74216eae2d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 1/30 [02:00<58:25, 120.89s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.900154113769531 | Iteration loss: 9.640345077514649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [03:57<55:06, 118.07s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.233695983886719 | Iteration loss: 9.659790134429931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 3/30 [05:49<51:55, 115.39s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.487876892089844 | Iteration loss: 9.689707336425782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 4/30 [07:42<49:39, 114.61s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.12053394317627 | Iteration loss: 9.654820346832276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 5/30 [09:43<48:44, 116.98s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.054527282714844 | Iteration loss: 9.687312698364257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 6/30 [11:46<47:32, 118.87s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.851830959320068 | Iteration loss: 9.705205402374268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 7/30 [13:43<45:22, 118.38s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.13048267364502 | Iteration loss: 9.692016277313233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 8/30 [15:37<42:52, 116.92s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.97271728515625 | Iteration loss: 9.67598051071167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 9/30 [17:33<40:50, 116.69s/it, Generating data]                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.993542671203613 | Iteration loss: 9.685272636413574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 10/30 [19:29<38:46, 116.35s/it, Current: Data 1/10 | Model 1/10 | Train Batch 2/5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.984212875366211 | Iteration loss: 9.674088802337646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 11/30 [21:26<36:55, 116.59s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.867478847503662 | Iteration loss: 9.683252582550049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 12/30 [23:24<35:08, 117.13s/it, Generating data]                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.865942001342773 | Iteration loss: 9.669565582275391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 13/30 [25:24<33:24, 117.92s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 8.02905559539795 | Iteration loss: 9.650641136169433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 14/30 [27:21<31:19, 117.49s/it, Current: Data 1/10 | Model 1/10 | Train Batch 1/5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.916713714599609 | Iteration loss: 9.676323013305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [29:16<29:11, 116.76s/it, Generating data]                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White box loss: 7.875517845153809 | Iteration loss: 9.67384437561035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [31:09<31:09, 124.62s/it, Current: Data 10/10 | Model 10/10 | Train Batch 4/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0368399620056152 GB\n"
     ]
    }
   ],
   "source": [
    "adv_snippet = loop(model, snippet, train_dataset, hooks, sot_ids, target_id, iters=30, mu=0.9, grad_mask=0.2, clamp_epsilon=0.005, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bd3cd8-e0c4-4e33-b8fe-6bdd3a685b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clamp: 0.005\n",
      "Prepare Method: prepare_front\n",
      "Snippet Size: (1, 1600)\n",
      "Position: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s, Valid Examples: 97 | Empty Sequences: 0 | Total SL = 18238]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total valid examples: 97\n",
      "Success rate (Empty): 0.0\n",
      "Success rate (ASL): 188.02061855670104 (attacked) out of 187.84536082474227 (original)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gradient.evaluate(model, adv_snippet, PrepareFront((1, 1600)), test_dataset, 0.005, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7d0a6-ed45-4dcc-8358-26a8d6c4f103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(gradient.audio_to_mel(snippet).squeeze()[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5787e-53fb-48a8-8697-1e517e5f4281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(gradient.audio_to_mel(adv_snippet.cpu()).squeeze()[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd47406-7584-459d-976b-3b57c8ee3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53b167-1368-43ab-aeb0-fef502d07d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu.print_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687aa9b9-ef90-4acb-bb95-4af7c20718c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
