{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5thx0SEBIIN"
   },
   "source": [
    "# Initialisation and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9rvOFi6QJP0z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc, math, traceback, os, datetime, logging\n",
    "from typing import Callable, Union, Optional\n",
    "from functools import partial\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import whisper\n",
    "from whisper.audio import N_FRAMES, N_SAMPLES\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EjUegebBNcX"
   },
   "source": [
    "# GPU RAM Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jobgOLtEeLpx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cuda_usage(msg: str = \"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{msg}{torch.cuda.memory_allocated(0)/(1024 ** 3)} GB\")\n",
    "\n",
    "def get_cuda_usage():\n",
    "    return torch.cuda.memory_allocated(0)/(1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1zjyFx78LvD-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNEPbtquUG_g"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aTrPYXKiygaU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "    print(\"Model deleted!\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zfgWJdLVJRbS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"tiny.en\"\n",
    "\n",
    "model = whisper.load_model(MODEL_NAME).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tolbjGxG7qB8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model.is_multilingual, num_languages=model.num_languages, language=\"en\", task=\"transcribe\")\n",
    "sot_ids = torch.tensor(tokenizer.sot_sequence_including_notimestamps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8P5xS3UBTfT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "upnfsCvahcEJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tedlium_path = \"../tedlium\"\n",
    "train_path, validation_path, test_path = f\"{tedlium_path}/train.hf\", f\"{tedlium_path}/validation.hf\", f\"{tedlium_path}/test.hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6166477f7024db1a605d926c54ee8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_SELECT = 500\n",
    "VALID_SELECT = 150\n",
    "TEST_SELECT = 250\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "tedlium_train = load_from_disk(train_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TRAIN_SELECT))\n",
    "tedlium_validation = load_from_disk(validation_path).with_format(\"torch\").shuffle(seed=SEED).select(range(VALID_SELECT))\n",
    "tedlium_test = load_from_disk(test_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TEST_SELECT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MoAt_Utrb4sT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(ls):\n",
    "    pad_to = max(list(map(lambda x: x[\"audio\"].shape[0], ls)))\n",
    "    return torch.cat(list(map(lambda x: F.pad(x[\"audio\"], (0, pad_to - x[\"audio\"].shape[0])).unsqueeze(0).to(torch.bfloat16), ls)), dim=0)\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1 # highly recommended to be 1\n",
    "VALID_BATCH_SIZE = 75\n",
    "\n",
    "train_dataset = DataLoader(tedlium_train, batch_size=TRAIN_BATCH_SIZE, collate_fn=collate)\n",
    "validation_dataset = DataLoader(tedlium_validation, batch_size=VALID_BATCH_SIZE, collate_fn=collate)\n",
    "test_dataset = DataLoader(tedlium_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY8-HSVPBYnZ"
   },
   "source": [
    "# Training Loop Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BzcVuVrg68uE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helpers involving model interaction and loss\n",
    "\n",
    "General flow is Audio Tensor --> Mel Tensor --> model.forward --> Logits --> Get log probabilities\n",
    "\"\"\"\n",
    "\n",
    "def audio_to_mel(audio: torch.Tensor) -> torch.Tensor:\n",
    "    return whisper.pad_or_trim(whisper.log_mel_spectrogram(audio, padding=N_SAMPLES),\n",
    "                              N_FRAMES)\n",
    "\n",
    "def audio_to_mel_batch(audio_batch: torch.Tensor) -> torch.Tensor:\n",
    "    if len(audio_batch.shape) == 1:\n",
    "        audio_batch = audio_batch.unsqueeze(0)\n",
    "    return torch.stack([audio_to_mel(audio) for audio in audio_batch])\n",
    "\n",
    "def mel_to_logits_batch(model: whisper.model.Whisper, mel_batch: torch.Tensor, sot_ids: torch.Tensor) -> torch.Tensor:\n",
    "    sot_ids = sot_ids.unsqueeze(0).expand(mel_batch.size(0), -1).to(device)\n",
    "    return model.forward(mel_batch, sot_ids)\n",
    "\n",
    "def get_loss_batch(logits: torch.Tensor, token_id: torch.Tensor) -> torch.Tensor:\n",
    "    sf = torch.nn.Softmax(dim=1)\n",
    "    log_probs = torch.log(sf(logits))\n",
    "    tgt_probs = log_probs[:,token_id].squeeze()\n",
    "    return -1 * torch.mean(tgt_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lf48eLc8U5Aj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utils to view mel\n",
    "\"\"\"\n",
    "\n",
    "def view_mel(audio: torch.Tensor) -> None:\n",
    "    mel = whisper.log_mel_spectrogram(audio)\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mel)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def mel_image(audio: torch.Tensor, pseudocolor_map: str = \"Blues\") -> torch.Tensor:\n",
    "    image = whisper.log_mel_spectrogram(audio.squeeze())\n",
    "    cm = colormaps[pseudocolor_map]\n",
    "    return torch.tensor(cm(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OHBIv30toPm3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Other utils\n",
    "\"\"\"\n",
    "\n",
    "# unused\n",
    "# def validate(model: whisper.model.Whisper, snippet: torch.Tensor, validation: torch.Tensor, \n",
    "#              prepare_method, tokenizer: whisper.tokenizer.Tokenizer) -> torch.Tensor:\n",
    "#     with torch.no_grad():\n",
    "#         validation = validation.to(device)\n",
    "#         attacked_data = prepare_method(snippet, validation)\n",
    "#         mel = audio_to_mel_batch(attacked_data)\n",
    "#         logits = mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "#         loss = get_loss_batch(logits, tokenizer.eot)\n",
    "#         return loss\n",
    "\n",
    "# check if any values in the snippet violate the clamp constraint\n",
    "def violates_clamp(snippet: torch.Tensor, clamp_epsilon: float) -> bool:\n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            return torch.any(torch.logical_or(snippet > clamp_epsilon, snippet < -clamp_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Audio Modification Helpers\n",
    "- Butterworth High Pass and Low Pass filters\n",
    "- Compressions (Mu Law and Inverse Mu Law for reversibility)\n",
    "\"\"\"\n",
    "\n",
    "def lowpass_filter(audio_tensor: torch.Tensor, cutoff: int, sampling_rate: int = 16_000, order: int = 5) -> torch.Tensor:\n",
    "    b, a = butter(order, cutoff, btype=\"lowpass\", fs=sampling_rate, analog=False)\n",
    "    y = lfilter(b, a, audio_tensor)\n",
    "    return torch.from_numpy(y).to(torch.float32)\n",
    "\n",
    "def highpass_filter(audio_tensor: torch.Tensor, cutoff: int, sampling_rate: int = 16_000, order: int = 5) -> torch.Tensor:\n",
    "    b, a = butter(order, cutoff, btype=\"highpass\", fs=sampling_rate, analog=False)\n",
    "    y = lfilter(b, a, audio_tensor)\n",
    "    return torch.from_numpy(y).to(torch.float32)\n",
    "\n",
    "################################################\n",
    "\n",
    "def mu_law(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    sign = torch.where(audio_tensor >= 0, 1, -1)\n",
    "    return sign * torch.log(1 + mu * torch.abs(audio_tensor)) / math.log(1 + mu)\n",
    "\n",
    "def inv_mu_law(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    sign = torch.where(audio_tensor >= 0, 1, -1)\n",
    "    return sign * (torch.tensor([mu + 1]).pow(torch.abs(audio_tensor)) - 1) / mu\n",
    "\n",
    "def mu_comp_decomp(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    return inv_mu_law(mu_law(audio_tensor, mu), mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK7qsqAVrTO3"
   },
   "source": [
    "# Attack Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "j7njJfPNpVSG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "every attack preparation method must:\n",
    "1. inherit from PrepareMethod (an abstract class)\n",
    "2. Override __call__\n",
    "\n",
    "* each example can either be a batch of audio tensors (M, N) or a single audio tensor (1, N)\n",
    "* the snippet must be of shape (1, N)\n",
    "\"\"\"\n",
    "class PrepareMethod(ABC):\n",
    "    def __init__(self, snippet_size: tuple, name: str):\n",
    "        assert len(snippet_size) == 2, f\"Snippet must have 2 dimensions, currently has {len(snippet_size)} dims\"\n",
    "        assert snippet_size[0] == 1, f\"Snippet must be of shape (1, N), currently of shape {snippet_size}\"\n",
    "        self.snippet_size = snippet_size\n",
    "        self.name = name\n",
    "    \n",
    "    def check_dims(self, snippet, example, desired_dims=2):\n",
    "        offenders = \"\"\n",
    "        if len(snippet.shape) != desired_dims:\n",
    "            offenders += f\"Need snippet (dims {len(snippet.shape)}, shape {snippet.shape}) to be of dims {desired_dims}\\n\"\n",
    "        if len(example.shape) != desired_dims:\n",
    "            offenders += f\"Need example (dims {len(example.shape)}, shape {example.shape}) to be of dims {desired_dims}\\n\"\n",
    "        if offenders:\n",
    "            raise ValueError(offenders.strip())\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, snippet, example):\n",
    "        pass\n",
    "    \n",
    "#################################\n",
    "\n",
    "class PrepareFront(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 10240), \"prepare_front\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return torch.cat([snippet, example], dim=1)\n",
    "\n",
    "#################################\n",
    "\n",
    "class PrepareOverlay(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return snippet + example\n",
    "    \n",
    "#################################\n",
    "\n",
    "class PrepareOverlayFront(PrepareMethod):\n",
    "    def __init__(self, snippet_size):\n",
    "        super().__init__(snippet_size, \"prepare_overlay_front\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        snippet = F.pad(snippet, (0, example.size(1) - snippet.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return snippet + example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mu-Law Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "                         \n",
    "class PrepareFrontMu(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay_mu\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return mu_law(torch.cat([snippet, example], dim=1))\n",
    "\n",
    "#################################\n",
    "                         \n",
    "class PrepareOverlayMu(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay_mu\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return mu_law(snippet + example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass-Filter Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unused Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unused\n",
    "def prepare_middle(snippet, example):\n",
    "    check_dims(snippet, \"snippet\")\n",
    "    check_dims(example, \"example\")\n",
    "    fragment1, fragment2 = torch.tensor_split(example, 2, dis=1)\n",
    "    snippet = snippet.repeat(example.size(0), 1)\n",
    "    return torch.cat([fragment1, snippet, fragment2])\n",
    "\n",
    "def prepare_back(snippet, example):\n",
    "    check_dims(snippet, \"snippet\")\n",
    "    check_dims(example, \"example\")\n",
    "    snippet = snippet.repeat(example.size(0), 1)\n",
    "    return torch.cat([example, snippet], dim=1)\n",
    "\n",
    "def prepare_overlay(snippet, example):\n",
    "    check_dims(snippet, \"snippet\")\n",
    "    check_dims(example, \"example\")\n",
    "    snippet = F.pad(snippet, (0, example.size(1) - snippet.size(1)), \"constant\", 0)\n",
    "    snippet = snippet.repeat(example.size(0), 1)\n",
    "    return snippet + example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEl7cH9fBbZb"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lejmrAxFOy5E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_autograd_track_snippet(model: whisper.model.Whisper,\n",
    "                      train_data: torch.utils.data.DataLoader, valid_data: torch.utils.data.DataLoader,\n",
    "                      prepare_method: PrepareMethod,\n",
    "                      writer: SummaryWriter = None,\n",
    "                      lr: float = 1e-3,\n",
    "                      iter_limit: int = None, mins_limit: int = None, patience: int = None, clamp_epsilon: float = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Runs the training loop and returns learned adversarial snippet.\n",
    "\n",
    "    Args:\n",
    "        model (whisper.model.Whisper)             : Whisper model\n",
    "        train_data (torch.utils.data.DataLoader)  : Training dataset\n",
    "        valid_data (torch.utils.data.DataLoader)  : Validation dataset\n",
    "        prepare_method (PrepareMethod)            : Preprocessing class that combines the adversarial snippet and the training data\n",
    "        writer (SummaryWriter)                    : Writer for the Tensorboard (Default is None)\n",
    "        lr (float)                                : Optimizer Learning Rate (Default is 1e-3)\n",
    "        iter_limit (int)                          : Epoch limit (Default is None)\n",
    "        mins_limit (int)                          : Time limit in minutes (Default is None)\n",
    "        patience (int)                            : Patience for Early Stopping (Default is None)\n",
    "        clamp_epsilon (float)                     : Value for L-Infinity clamping of the snippet. If None, does not clamp (Default is None)\n",
    "\n",
    "    Returns:\n",
    "        snippet (torch.Tensor)                    : Learned adversarial snippet\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise stuff\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "    loss = torch.tensor(np.inf, requires_grad=True)\n",
    "    num_training_batches = len(train_data)\n",
    "    num_valid_batches = len(valid_data)\n",
    "\n",
    "    time_limit = mins_limit * 60 if mins_limit else None\n",
    "\n",
    "    snippet = torch.rand(prepare_method.snippet_size, requires_grad=True, device=device) # adversarial snippet\n",
    "    \n",
    "    snippets = [snippet]\n",
    "    \n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            snippet = snippet * clamp_epsilon\n",
    "    snippet.requires_grad = True\n",
    "\n",
    "    optim = torch.optim.AdamW([snippet], lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.5)\n",
    "\n",
    "    attack_stack, attacked_data, mel, logits, pbar, avg_valid_loss = None, None, None, None, None, None\n",
    "    lowest_valid_loss = np.inf\n",
    "    curr_patience = patience\n",
    "    best_snippet = snippet.detach().clone()\n",
    "\n",
    "    # display attack method and snippet for sanity check\n",
    "    print(f\"Prepare method: {prepare_method.name}\")\n",
    "    print(f\"Snippet initialised to [{torch.min(snippet)}, {torch.max(snippet)}] of size {prepare_method.snippet_size}\")\n",
    "    print(f\"Clamp: {clamp_epsilon}\\nTime Limit (Mins): {mins_limit}\\nEpochs Limit: {iter_limit}\")\n",
    "\n",
    "    # log attack snippet\n",
    "    if writer:\n",
    "        writer.add_image(\"Attack Snippet\", mel_image(snippet.detach().to(\"cpu\")), 0, dataformats=\"HWC\")\n",
    "        writer.flush()\n",
    "\n",
    "    # progress bar\n",
    "    pbar = tqdm(range(1), desc=\"Training\", ncols=0)\n",
    "    itera = 0\n",
    "\n",
    "    # track gpu usage\n",
    "    base_cuda_usage = get_cuda_usage()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            itera += 1\n",
    "            if iter_limit:\n",
    "                iter_limit -= 1\n",
    "                if iter_limit <= 0:\n",
    "                    pbar.set_postfix_str(\"Epoch limit reached! Terminating...\")\n",
    "                    break\n",
    "            if time_limit and pbar.format_dict[\"elapsed\"] >= time_limit:\n",
    "                pbar.set_postfix_str(\"Time limit reached! Terminating...\")\n",
    "                break\n",
    "            if patience and avg_valid_loss:\n",
    "                if curr_patience <= 0:\n",
    "                    pbar.set_postfix_str(\"Patience expired! Terminating...\")\n",
    "                    break\n",
    "            if clamp_epsilon and violates_clamp(snippet, clamp_epsilon):\n",
    "                raise ValueError(\"Snippet values violate clamp constraint!!\")\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_valid_loss = 0\n",
    "            total_cuda_usage_iter = 0\n",
    "\n",
    "            for batch_no, batch in enumerate(train_data):\n",
    "                pbar.set_postfix_str(f\"Iter {itera}, Training Batch {batch_no + 1}/{num_training_batches}\")\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                attacked_data = prepare_method(snippet, batch)\n",
    "\n",
    "                # forward prop\n",
    "                mel = audio_to_mel_batch(attacked_data)\n",
    "                logits = mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                loss = get_loss_batch(logits, tokenizer.eot)\n",
    "                \n",
    "                # get training metrics\n",
    "                total_cuda_usage_iter += get_cuda_usage()\n",
    "                avg_training_loss += loss.detach()\n",
    "\n",
    "                # backprop\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                # clamp snippet\n",
    "                if clamp_epsilon:\n",
    "                    with torch.no_grad():\n",
    "                        snippet.clamp_(min=-clamp_epsilon, max=clamp_epsilon)\n",
    "                        \n",
    "                snippet.requires_grad = True\n",
    "                batch.to(\"cpu\")\n",
    "            \n",
    "            snippets.append(snippet.detach().clone())\n",
    "            avg_training_loss /= len(train_data)\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                for batch_no, v in enumerate(valid_data):\n",
    "                    pbar.set_postfix_str(f\"Iter {itera}, Validation Batch {batch_no + 1}/{num_valid_batches}\")\n",
    "                    v = v.to(device)\n",
    "                    attacked_data_valid = prepare_method(snippet, v)\n",
    "                    mel_valid = audio_to_mel_batch(attacked_data_valid)\n",
    "                    logits_valid = mel_to_logits_batch(model, mel_valid, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                    avg_valid_loss += get_loss_batch(logits_valid, tokenizer.eot)\n",
    "            avg_valid_loss /= num_valid_batches\n",
    "            \n",
    "            # track lowest valid loss and save the snippet with lowest valid loss\n",
    "            if avg_valid_loss >= lowest_valid_loss:\n",
    "                curr_patience -= 1\n",
    "            else:\n",
    "                curr_patience = patience\n",
    "                lowest_valid_loss = avg_valid_loss\n",
    "                best_snippet = snippet.detach().clone()\n",
    "\n",
    "            pbar.write(f\"Trng Avg Loss: {avg_training_loss} | Valid Avg Loss: {avg_valid_loss} | Patience: {curr_patience} | LR: {scheduler.get_last_lr()} | Epoch Limit: {iter_limit}\")\n",
    "\n",
    "            if writer:\n",
    "              # log training and validation losses\n",
    "                writer.add_scalar(\"Training average loss\", avg_training_loss, itera)\n",
    "                writer.add_scalar(\"Validation average loss\", avg_valid_loss, itera)\n",
    "\n",
    "                # log GPU RAM usage\n",
    "                if torch.cuda.is_available():\n",
    "                    writer.add_scalar(\"GPU RAM Usage\", total_cuda_usage_iter / num_training_batches - base_cuda_usage, itera)\n",
    "\n",
    "              # log attack snippet and flush\n",
    "                writer.add_image(\"Attack Snippet\", mel_image(snippet.detach().to(\"cpu\")), itera, dataformats=\"HWC\")\n",
    "                writer.flush()\n",
    "            \n",
    "            # LR decay\n",
    "            scheduler.step()\n",
    "            \n",
    "            # refresh pbar to (hopefully) force update of progress bar\n",
    "            pbar.refresh()\n",
    "\n",
    "    except Exception as e:\n",
    "        # need to explicitly close pbar here so traceback can print error\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "            traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # close pbar to free stdout/stdsys (cant rmb which one)\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "\n",
    "        # clear tensors from GPU memory to\n",
    "        # prevent memory leak\n",
    "        if attacked_data is not None:\n",
    "            attacked_data.to(\"cpu\")\n",
    "            del attacked_data\n",
    "            print(\"Cleared attacked data\")\n",
    "\n",
    "        if attack_stack is not None:\n",
    "            attack_stack.to(\"cpu\")\n",
    "            del attack_stack\n",
    "            print(\"Cleared attack stack\")\n",
    "\n",
    "        if mel is not None:\n",
    "            mel.to(\"cpu\")\n",
    "            del mel\n",
    "            print(\"Cleared mel\")\n",
    "\n",
    "        if logits is not None:\n",
    "            logits.to(\"cpu\")\n",
    "            del logits\n",
    "            print(\"Cleared logits\")\n",
    "\n",
    "        loss.to(\"cpu\")\n",
    "        del loss\n",
    "        print(\"Cleared loss\")\n",
    "\n",
    "        # empty GPU cache and garbage collect\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print_cuda_usage()\n",
    "        \n",
    "        return best_snippet.detach().to(\"cpu\"), snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JML5ybTKPMEu",
    "outputId": "f3650f0c-d671-4acf-ae9f-40bc0e620d18",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14174842834472656 GB\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jTU811FhsXQn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "PATIENCE = 5\n",
    "MIN_LIMIT = 45\n",
    "ITER_LIMIT = 30\n",
    "CLAMP_EP = 0.005\n",
    "PREPARE_METHOD = PrepareFront()\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "timestamp = datetime.datetime.now().strftime(f'%Y%m%d-%H%M%S_clamp_{CLAMP_EP}_{PREPARE_METHOD.name}')\n",
    "writer = SummaryWriter(log_dir=f\"../runs/clamp_tests/{timestamp}\", max_queue=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBzfVKNgHYp",
    "outputId": "80ab88a8-906c-4d44-a477-98b8717e3fc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare method: prepare_front\n",
      "Snippet initialised to [4.4394806764103123e-07, 0.004999728873372078] of size (1, 10240)\n",
      "Clamp: 0.005\n",
      "Time Limit (Mins): 45\n",
      "Epochs Limit: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [02:44<?, ?it/s, Iter 2, Training Batch 2/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 2.836932897567749 | Valid Avg Loss: 1.6088218688964844 | Patience: 5 | LR: [0.001] | Epoch Limit: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [03:57<?, ?it/s, Iter 3, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.1791659593582153 | Valid Avg Loss: 2.8378710746765137 | Patience: 4 | LR: [0.001] | Epoch Limit: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [05:14<?, ?it/s, Iter 4, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.6730355620384216 | Valid Avg Loss: 0.6361373662948608 | Patience: 5 | LR: [0.001] | Epoch Limit: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [06:27<?, ?it/s, Iter 5, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.3557809591293335 | Valid Avg Loss: 0.5112988948822021 | Patience: 5 | LR: [0.001] | Epoch Limit: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [07:38<?, ?it/s, Iter 6, Training Batch 2/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.4094109833240509 | Valid Avg Loss: 1.808210849761963 | Patience: 4 | LR: [0.001] | Epoch Limit: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [08:44<?, ?it/s, Iter 7, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.5924119353294373 | Valid Avg Loss: 0.6881767511367798 | Patience: 3 | LR: [0.0005] | Epoch Limit: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [09:54<?, ?it/s, Iter 8, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.16903938353061676 | Valid Avg Loss: 0.17731736600399017 | Patience: 5 | LR: [0.0005] | Epoch Limit: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [11:09<?, ?it/s, Iter 9, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.14695902168750763 | Valid Avg Loss: 0.6453249454498291 | Patience: 4 | LR: [0.0005] | Epoch Limit: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [12:24<?, ?it/s, Iter 10, Training Batch 1/500] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.20221887528896332 | Valid Avg Loss: 0.4141353368759155 | Patience: 3 | LR: [0.0005] | Epoch Limit: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [13:39<?, ?it/s, Iter 11, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.244817316532135 | Valid Avg Loss: 0.345146119594574 | Patience: 2 | LR: [0.0005] | Epoch Limit: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [14:49<?, ?it/s, Iter 11, Validation Batch 2/2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.02494276873767376 | Valid Avg Loss: 0.0560571625828743 | Patience: 5 | LR: [0.00025] | Epoch Limit: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [16:04<?, ?it/s, Iter 12, Validation Batch 2/2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.008644790388643742 | Valid Avg Loss: 0.0300020482391119 | Patience: 5 | LR: [0.00025] | Epoch Limit: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [17:17<?, ?it/s, Iter 14, Training Batch 2/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0035787627566605806 | Valid Avg Loss: 0.02228453755378723 | Patience: 5 | LR: [0.00025] | Epoch Limit: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [18:33<?, ?it/s, Iter 15, Training Batch 2/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0019110959256067872 | Valid Avg Loss: 0.012878228910267353 | Patience: 5 | LR: [0.00025] | Epoch Limit: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [19:44<?, ?it/s, Iter 16, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0010811749380081892 | Valid Avg Loss: 0.010345084592700005 | Patience: 5 | LR: [0.00025] | Epoch Limit: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [20:58<?, ?it/s, Iter 17, Training Batch 1/500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0007402893388643861 | Valid Avg Loss: 0.008961635641753674 | Patience: 5 | LR: [0.000125] | Epoch Limit: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [22:50<?, ?it/s, Iter 17, Validation Batch 2/2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0005947555182501674 | Valid Avg Loss: 0.008399022743105888 | Patience: 5 | LR: [0.000125] | Epoch Limit: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [25:40<?, ?it/s, Iter 18, Validation Batch 2/2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.0005040719988755882 | Valid Avg Loss: 0.008231228217482567 | Patience: 5 | LR: [0.000125] | Epoch Limit: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [28:13<?, ?it/s, Iter 19, Validation Batch 2/2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.00044979146332480013 | Valid Avg Loss: 0.007953798398375511 | Patience: 5 | LR: [0.000125] | Epoch Limit: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [28:22<?, ?it/s, Iter 20, Training Batch 50/500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared attacked data\n",
      "Cleared mel\n",
      "Cleared logits\n",
      "Cleared loss\n",
      "0.5802798271179199 GB\n"
     ]
    }
   ],
   "source": [
    "best_snippet, snippets = training_autograd_track_snippet(model, train_dataset, validation_dataset, \n",
    "                                                            PREPARE_METHOD,\n",
    "                                                            writer, lr=LR, \n",
    "                                                            iter_limit=ITER_LIMIT, mins_limit=MIN_LIMIT, patience=PATIENCE, clamp_epsilon=CLAMP_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "q59EbCsIfr-9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_mel(best_snippet.detach().to(\"cpu\").squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-kaeGzDCEUV"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uYCZCjkitb0J",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clamp: 0.005\n",
      "Prepare Method: prepare_front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|| 250/250 [00:31<00:00,  7.93it/s, Valid Examples: 194 | Empty Sequences: 194 | Total SL = 0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total valid examples: 194\n",
      "Success rate (Empty): 1.0\n",
      "Success rate (ASL): 0.0 (attacked) out of 122.16494845360825 (original)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "# for now, metric is whether the transcription is empty or consists only of blank tokens\n",
    "\n",
    "def evaluate(snippet, prepare_method, model, test_dataset):\n",
    "    print(f\"Clamp: {CLAMP_EP}\\nPrepare Method: {prepare_method.name}\")\n",
    "    empty_counter = 0\n",
    "    char_counter = 0\n",
    "    total_examples = 0\n",
    "    original_chars = 0\n",
    "\n",
    "    snippet = snippet.to(device)\n",
    "    pbar = tqdm(range(len(test_dataset)), desc=\"Inference\")\n",
    "    test_dataset_iter = iter(test_dataset)\n",
    "    model.eval()\n",
    "\n",
    "    for i in pbar:\n",
    "        # evaluate if there are any words at all\n",
    "        example, answer = next(test_dataset_iter).values()\n",
    "        if isinstance(answer, tuple) or isinstance(answer, list):\n",
    "            answer = answer[0]\n",
    "        if answer != \"ignore_time_segment_in_scoring\":\n",
    "            attacked_example = prepare_method(snippet, example.to(device))\n",
    "            transcription = model.transcribe(attacked_example.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"]\n",
    "\n",
    "            if not transcription.strip():\n",
    "                empty_counter += 1\n",
    "            char_counter += len(transcription.strip())\n",
    "            original_chars += len(answer)\n",
    "            total_examples += 1\n",
    "            pbar.set_postfix_str(f\"Valid Examples: {total_examples} | Empty Sequences: {empty_counter} | Total SL = {char_counter}\")\n",
    "\n",
    "        example.to(\"cpu\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"\\n\")\n",
    "    print(f\"Total valid examples: {total_examples}\")\n",
    "    print(f\"Success rate (Empty): {empty_counter/total_examples}\")\n",
    "    print(f\"Success rate (ASL): {char_counter/total_examples} (attacked) out of {original_chars/total_examples} (original)\")\n",
    "\n",
    "evaluate(best_snippet, PREPARE_METHOD, model, test_dataset) # commented to prevent the runtime from autorunning and crashing the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 10240])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets = torch.stack(snippets)\n",
    "snippets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(snippets.squeeze(), \"snippets.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hVIWKQO1V22"
   },
   "source": [
    "# Save and Hear Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise(random_snippet, ep):\n",
    "    # we assume torch.rand inits to [0, 1)\n",
    "    res = random_snippet * ep * 2 - ep\n",
    "    print(f\"Normalised, Min {torch.min(res)}, Max {torch.max(res)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pD8MUV-y1Rsj"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save snippet to wav file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msave_audio\u001b[49m(snippet, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./snippets/clamp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCLAMP_EP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREPARE_METHOD\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_snippet_only.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_audio' is not defined"
     ]
    }
   ],
   "source": [
    "# Save snippet to wav file\n",
    "save_audio(snippet, f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_snippet_only.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTI3OCNw5681"
   },
   "outputs": [],
   "source": [
    "save_audio(PREPARE_METHOD(snippet.to(\"cpu\"), tedlium_test[2][\"audio\"].unsqueeze(0)), f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_combined.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
