{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358cb50a-fd69-410a-9575-90ebc949a229",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialisation\n",
    "- Mount persistent libraries\n",
    "- Configure protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1369ce47-94c1-4546-83d0-1ffec1765b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a523ee-f8cf-49b0-873f-816b94fe8b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Collecting protobuf==3.20.1\n",
      "  Downloading http://192.168.16.2:8080/root/pypi/%2Bf/69c/cfdf3657ba595/protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 103.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "cudf 23.2.0 requires protobuf==3.20.3, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\n",
      "Successfully installed protobuf-3.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# necessary for whisperx to import correctly\n",
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "!pip install --upgrade protobuf==3.20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9533b-f6a0-4bce-a7c9-a1bb8b4314a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WhisperX Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af6704af-0e41-4973-ac75-1e0efbdf8440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a741d4b-8848-4c32-ad11-842e60b6db1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint libs/whisperx/assets/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "batch_size = 32 # reduce if low on GPU mem\n",
    "compute_type = \"float32\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "\n",
    "model = whisperx.load_model(\"tiny.en\", device, compute_type=compute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16c8921-60a5-4d8c-960e-7c3282304549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tedlium = load_dataset(\"AudioLLMs/tedlium3_test\", streaming=True)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e805f10-81c4-43c8-95c7-02736628f042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_tedlium3(model, data: dict, has_gpu=False) -> None:\n",
    "    dtype = np.float32 if not has_gpu else np.float16\n",
    "    transformed_data = data[\"context\"][\"array\"].astype(dtype)\n",
    "    results = model.transcribe(transformed_data)\n",
    "    print(f\"Transcription: {results['segments'][0]['text']}\\nActual: {data['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d398ea1-b8a0-47e2-91ae-e78198ab0379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "iter_tedlium = iter(tedlium)\n",
    "for i in range(3):\n",
    "    samples.append(next(iter_tedlium))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c952e7d8-e238-477c-b18a-e03185024214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  I'd like to share with you a discovery that I made a few months ago while writing an article for Italian Wired. I always keep my desires handy whenever I'm writing anything, but\n",
      "Actual: i 'd like to share with you a discovery that i made a few months ago while writing an article for italian wired i always keep my thesaurus handy whenever i 'm writing anything but\n",
      "\n",
      "\n",
      "Transcription:  I had already finished editing the piece and I realized that I had never once in my life looked up the word disabled to see what I'd find. Let me redo the entry.\n",
      "Actual: i 'd already finished editing the piece and i realized that i had never once in my life looked up the word disabled to see what i 'd find let me read you the entry\n",
      "\n",
      "\n",
      "Transcription:  Disables, adjectives, crippled, helpless, useless, wrecked.\n",
      "Actual: disabled adjective crippled helpless useless wrecked\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    infer_tedlium3(model, sample)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
