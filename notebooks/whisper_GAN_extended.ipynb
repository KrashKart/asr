{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5thx0SEBIIN"
   },
   "source": [
    "# Initialisation and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '/home/jovyan/libs'\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9rvOFi6QJP0z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc, math, traceback, datetime\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import whisper\n",
    "from whisper.audio import N_FRAMES, N_SAMPLES\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EjUegebBNcX"
   },
   "source": [
    "# GPU RAM Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jobgOLtEeLpx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cuda_usage(msg: str = \"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{msg}{torch.cuda.memory_allocated(0)/(1024 ** 3)} GB\")\n",
    "\n",
    "def get_cuda_usage():\n",
    "    return torch.cuda.memory_allocated(0)/(1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1zjyFx78LvD-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNEPbtquUG_g"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aTrPYXKiygaU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "    print(\"Model deleted!\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zfgWJdLVJRbS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/libs/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"tiny.en\"\n",
    "\n",
    "model = whisper.load_model(MODEL_NAME).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tolbjGxG7qB8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model.is_multilingual, num_languages=model.num_languages, language=\"en\", task=\"transcribe\")\n",
    "sot_ids = torch.tensor(tokenizer.sot_sequence_including_notimestamps, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8P5xS3UBTfT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "upnfsCvahcEJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tedlium_path = \"../tedlium\"\n",
    "train_path, validation_path, test_path = f\"{tedlium_path}/train_idx.hf\", f\"{tedlium_path}/validation_idx.hf\", f\"{tedlium_path}/test.hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead8db1092004d56af6206d06807d1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_SELECT = 500\n",
    "VALID_SELECT = 150\n",
    "TEST_SELECT = 250\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "tedlium_train = load_from_disk(train_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TRAIN_SELECT))\n",
    "tedlium_validation = load_from_disk(validation_path).with_format(\"torch\").shuffle(seed=SEED).select(range(VALID_SELECT))\n",
    "tedlium_test = load_from_disk(test_path).with_format(\"torch\").shuffle(seed=SEED).select(range(TEST_SELECT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "MoAt_Utrb4sT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(ls):\n",
    "    pad_to = max(list(map(lambda x: x[\"audio\"].shape[0], ls)))\n",
    "    return torch.cat(list(map(lambda x: F.pad(x[\"audio\"], (0, pad_to - x[\"audio\"].shape[0])).unsqueeze(0).to(torch.bfloat16), ls)), dim=0)\n",
    "\n",
    "def collate_idx(ls):\n",
    "    return ls[0][\"audio\"].unsqueeze(0), ls[0][\"idx\"].item()\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1 # highly recommended to be 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = DataLoader(tedlium_train, batch_size=TRAIN_BATCH_SIZE, collate_fn=collate_idx)\n",
    "validation_dataset = DataLoader(tedlium_validation, batch_size=VALID_BATCH_SIZE, collate_fn=collate_idx)\n",
    "test_dataset = DataLoader(tedlium_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY8-HSVPBYnZ"
   },
   "source": [
    "# Training Loop Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BzcVuVrg68uE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helpers involving model interaction and loss\n",
    "\n",
    "General flow is Audio Tensor --> Mel Tensor --> model.forward --> Logits --> Get log probabilities\n",
    "\"\"\"\n",
    "\n",
    "def audio_to_mel(audio: torch.Tensor) -> torch.Tensor:\n",
    "    return whisper.pad_or_trim(whisper.log_mel_spectrogram(audio, padding=N_SAMPLES),\n",
    "                              N_FRAMES)\n",
    "\n",
    "def audio_to_mel_batch(audio_batch: torch.Tensor) -> torch.Tensor:\n",
    "    if len(audio_batch.shape) == 1:\n",
    "        audio_batch = audio_batch.unsqueeze(0)\n",
    "    return torch.stack([audio_to_mel(audio) for audio in audio_batch])\n",
    "\n",
    "def mel_to_logits_batch(model: whisper.model.Whisper, mel_batch: torch.Tensor, sot_ids: torch.Tensor) -> torch.Tensor:\n",
    "    sot_ids = sot_ids.unsqueeze(0).expand(mel_batch.size(0), -1).to(device)\n",
    "    return model.forward(mel_batch, sot_ids)\n",
    "\n",
    "def get_loss_batch(logits: torch.Tensor, token_id: torch.Tensor) -> torch.Tensor:\n",
    "    sf = torch.nn.Softmax(dim=1)\n",
    "    log_probs = torch.log(sf(logits))\n",
    "    tgt_probs = log_probs[:,token_id].squeeze()\n",
    "    return -1 * torch.mean(tgt_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "lf48eLc8U5Aj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utils to view mel\n",
    "\"\"\"\n",
    "\n",
    "def view_mel(audio: torch.Tensor) -> None:\n",
    "    mel = whisper.log_mel_spectrogram(audio)\n",
    "    print(mel.shape)\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mel)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def mel_image(audio: torch.Tensor, pseudocolor_map: str = \"Blues\") -> torch.Tensor:\n",
    "    image = whisper.log_mel_spectrogram(audio.squeeze())\n",
    "    cm = colormaps[pseudocolor_map]\n",
    "    return torch.tensor(cm(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OHBIv30toPm3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Other utils\n",
    "\"\"\"\n",
    "\n",
    "# unused\n",
    "# def validate(model: whisper.model.Whisper, snippet: torch.Tensor, validation: torch.Tensor, \n",
    "#              prepare_method, tokenizer: whisper.tokenizer.Tokenizer) -> torch.Tensor:\n",
    "#     with torch.no_grad():\n",
    "#         validation = validation.to(device)\n",
    "#         attacked_data = prepare_method(snippet, validation)\n",
    "#         mel = audio_to_mel_batch(attacked_data)\n",
    "#         logits = mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "#         loss = get_loss_batch(logits, tokenizer.eot)\n",
    "#         return loss\n",
    "\n",
    "# check if any values in the snippet violate the clamp constraint\n",
    "def violates_clamp(snippet: torch.Tensor, clamp_epsilon: float) -> bool:\n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            return torch.any(torch.logical_or(snippet > clamp_epsilon, snippet < -clamp_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Audio Modification Helpers\n",
    "- Butterworth High Pass and Low Pass filters\n",
    "- Compressions (Mu Law and Inverse Mu Law for reversibility)\n",
    "\"\"\"\n",
    "\n",
    "def lowpass_filter(audio_tensor: torch.Tensor, cutoff: int, sampling_rate: int = 16_000, order: int = 5) -> torch.Tensor:\n",
    "    b, a = butter(order, cutoff, btype=\"lowpass\", fs=sampling_rate, analog=False)\n",
    "    y = lfilter(b, a, audio_tensor)\n",
    "    return torch.from_numpy(y).to(torch.float32)\n",
    "\n",
    "def highpass_filter(audio_tensor: torch.Tensor, cutoff: int, sampling_rate: int = 16_000, order: int = 5) -> torch.Tensor:\n",
    "    b, a = butter(order, cutoff, btype=\"highpass\", fs=sampling_rate, analog=False)\n",
    "    y = lfilter(b, a, audio_tensor)\n",
    "    return torch.from_numpy(y).to(torch.float32)\n",
    "\n",
    "################################################\n",
    "\n",
    "def mu_law(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    sign = torch.where(audio_tensor >= 0, 1, -1)\n",
    "    return sign * torch.log(1 + mu * torch.abs(audio_tensor)) / math.log(1 + mu)\n",
    "\n",
    "def inv_mu_law(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    sign = torch.where(audio_tensor >= 0, 1, -1)\n",
    "    return sign * (torch.tensor([mu + 1]).pow(torch.abs(audio_tensor)) - 1) / mu\n",
    "\n",
    "def mu_comp_decomp(audio_tensor: torch.Tensor, mu: int = 255) -> torch.Tensor:\n",
    "    return inv_mu_law(mu_law(audio_tensor, mu), mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK7qsqAVrTO3"
   },
   "source": [
    "# Attack Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "j7njJfPNpVSG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "every attack preparation method must:\n",
    "1. inherit from PrepareMethod (an abstract class)\n",
    "2. Override __call__\n",
    "\n",
    "* each example can either be a batch of audio tensors (M, N) or a single audio tensor (1, N)\n",
    "* the snippet must be of shape (1, N)\n",
    "\"\"\"\n",
    "class PrepareMethod(ABC):\n",
    "    def __init__(self, snippet_size: tuple, name: str):\n",
    "        assert len(snippet_size) == 2, f\"Snippet must have 2 dimensions, currently has {len(snippet_size)} dims\"\n",
    "        assert snippet_size[0] == 1, f\"Snippet must be of shape (1, N), currently of shape {snippet_size}\"\n",
    "        self.snippet_size = snippet_size\n",
    "        self.name = name\n",
    "    \n",
    "    def check_dims(self, snippet, example, desired_dims=2):\n",
    "        offenders = \"\"\n",
    "        if len(snippet.shape) != desired_dims:\n",
    "            offenders += f\"Need snippet (dims {len(snippet.shape)}, shape {snippet.shape}) to be of dims {desired_dims}\\n\"\n",
    "        if len(example.shape) != desired_dims:\n",
    "            offenders += f\"Need example (dims {len(example.shape)}, shape {example.shape}) to be of dims {desired_dims}\\n\"\n",
    "        if offenders:\n",
    "            raise ValueError(offenders.strip())\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, snippet, example):\n",
    "        pass\n",
    "    \n",
    "#################################\n",
    "\n",
    "class PrepareFront(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 10240), \"prepare_front\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return torch.cat([snippet, example], dim=1)\n",
    "\n",
    "#################################\n",
    "\n",
    "class PrepareOverlay(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return snippet + example\n",
    "    \n",
    "#################################\n",
    "\n",
    "class PrepareOverlayFront(PrepareMethod):\n",
    "    def __init__(self, snippet_size):\n",
    "        super().__init__(snippet_size, \"prepare_overlay_front\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        snippet = F.pad(snippet, (0, example.size(1) - snippet.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return snippet + example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mu-Law Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "                         \n",
    "class PrepareFrontMu(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay_mu\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return mu_law(torch.cat([snippet, example], dim=1))\n",
    "\n",
    "#################################\n",
    "                         \n",
    "class PrepareOverlayMu(PrepareMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__((1, 480_000), \"prepare_overlay_mu\")\n",
    "    \n",
    "    def __call__(self, snippet, example):\n",
    "        self.check_dims(snippet, example)\n",
    "        example = F.pad(example, (0, snippet.size(1) - example.size(1)), \"constant\", 0)\n",
    "        snippet = snippet.repeat(example.size(0), 1)\n",
    "        return mu_law(snippet + example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass-Filter Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEl7cH9fBbZb"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "lejmrAxFOy5E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_autograd_more(model: whisper.model.Whisper,\n",
    "                      train_data: torch.utils.data.DataLoader, valid_data: torch.utils.data.DataLoader,\n",
    "                      prepare_method: PrepareMethod,\n",
    "                      writer: SummaryWriter = None,\n",
    "                      lr: float = 1e-3,\n",
    "                      iter_limit: int = None, mins_limit: int = None, patience: int = None, clamp_epsilon: float = None) -> torch.Tensor:\n",
    "    \n",
    "    # initialise stuff\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "    loss = torch.tensor(np.inf, requires_grad=True)\n",
    "    num_training_batches = len(train_data)\n",
    "    num_valid_batches = len(valid_data)\n",
    "\n",
    "    time_limit = mins_limit * 60 if mins_limit else None\n",
    "\n",
    "    snippet = torch.rand(prepare_method.snippet_size, requires_grad=True, device=device) # adversarial snippet\n",
    "    \n",
    "    snippets = [snippet]\n",
    "    buffer = None\n",
    "    train_success = dict()\n",
    "    valid_success = dict()\n",
    "    \n",
    "    if clamp_epsilon:\n",
    "        with torch.no_grad():\n",
    "            snippet = snippet * clamp_epsilon\n",
    "    snippet.requires_grad = True\n",
    "\n",
    "    optim = torch.optim.AdamW([snippet], lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.5)\n",
    "\n",
    "    attack_stack, attacked_data, mel, logits, pbar, avg_valid_loss = None, None, None, None, None, None\n",
    "    lowest_valid_loss = np.inf\n",
    "    curr_patience = patience\n",
    "    best_snippet = snippet.detach().clone()\n",
    "\n",
    "    # display attack method and snippet for sanity check\n",
    "    print(f\"Prepare method: {prepare_method.name}\")\n",
    "    print(f\"Snippet initialised to [{torch.min(snippet)}, {torch.max(snippet)}] of size {prepare_method.snippet_size}\")\n",
    "    print(f\"Clamp: {clamp_epsilon}\\nTime Limit (Mins): {mins_limit}\\nEpochs Limit: {iter_limit}\")\n",
    "\n",
    "    # log attack snippet\n",
    "    if writer:\n",
    "        writer.add_image(\"Attack Snippet\", mel_image(snippet.detach().to(\"cpu\")), 0, dataformats=\"HWC\")\n",
    "        writer.flush()\n",
    "\n",
    "    # progress bar\n",
    "    pbar = tqdm(range(1), desc=\"Training\", ncols=0)\n",
    "    itera = 0\n",
    "\n",
    "    # track gpu usage\n",
    "    base_cuda_usage = get_cuda_usage()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = torch.zeros((len(train_data), 1))\n",
    "            itera += 1\n",
    "            if iter_limit:\n",
    "                iter_limit -= 1\n",
    "                if iter_limit <= 0:\n",
    "                    pbar.set_postfix_str(\"Epoch limit reached! Terminating...\")\n",
    "                    break\n",
    "            if time_limit and pbar.format_dict[\"elapsed\"] >= time_limit:\n",
    "                pbar.set_postfix_str(\"Time limit reached! Terminating...\")\n",
    "                break\n",
    "            if patience and avg_valid_loss:\n",
    "                if curr_patience <= 0:\n",
    "                    pbar.set_postfix_str(\"Patience expired! Terminating...\")\n",
    "                    break\n",
    "            if clamp_epsilon and violates_clamp(snippet, clamp_epsilon):\n",
    "                raise ValueError(\"Snippet values violate clamp constraint!!\")\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_valid_loss = 0\n",
    "            total_cuda_usage_iter = 0\n",
    "\n",
    "            for batch_no, (batch, idx) in enumerate(train_data):\n",
    "                pbar.set_postfix_str(f\"Iter {itera}, Training Batch {batch_no + 1}/{num_training_batches}\")\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                attacked_data = prepare_method(snippet, batch)\n",
    "\n",
    "                # forward prop\n",
    "                mel = audio_to_mel_batch(attacked_data)\n",
    "                logits = mel_to_logits_batch(model, mel, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                loss = get_loss_batch(logits, tokenizer.eot)\n",
    "                \n",
    "                # get training metrics\n",
    "                total_cuda_usage_iter += get_cuda_usage()\n",
    "                avg_training_loss += loss.detach()\n",
    "\n",
    "                # backprop\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                # clamp snippet\n",
    "                if clamp_epsilon:\n",
    "                    with torch.no_grad():\n",
    "                        snippet.clamp_(min=-clamp_epsilon, max=clamp_epsilon)\n",
    "                        \n",
    "                snippet.requires_grad = True\n",
    "                batch.to(\"cpu\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    seq_length = len(model.transcribe(attacked_data.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                    train_success[idx] = train_success.get(idx, []) + [seq_length]\n",
    "            \n",
    "            snippets.append(snippet.detach().clone())\n",
    "            avg_training_loss /= len(train_data)\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                for batch_no, (v, idx) in enumerate(valid_data):\n",
    "                    pbar.set_postfix_str(f\"Iter {itera}, Validation Batch {batch_no + 1}/{num_valid_batches}\")\n",
    "                    v = v.to(device)\n",
    "                    attacked_data_valid = prepare_method(snippet, v)\n",
    "                    mel_valid = audio_to_mel_batch(attacked_data_valid)\n",
    "                    logits_valid = mel_to_logits_batch(model, mel_valid, sot_ids)[:,-1,:].squeeze(dim=1)\n",
    "                    avg_valid_loss += get_loss_batch(logits_valid, tokenizer.eot)\n",
    "                    \n",
    "                    seq_length = len(model.transcribe(attacked_data_valid.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"])\n",
    "                    valid_success[idx] = valid_success.get(idx, []) + [seq_length] \n",
    "            avg_valid_loss /= num_valid_batches\n",
    "            \n",
    "            # track lowest valid loss and save the snippet with lowest valid loss\n",
    "            if avg_valid_loss >= lowest_valid_loss:\n",
    "                curr_patience -= 1\n",
    "            else:\n",
    "                curr_patience = patience\n",
    "                lowest_valid_loss = avg_valid_loss\n",
    "                best_snippet = snippet.detach().clone()\n",
    "\n",
    "            pbar.write(f\"Trng Avg Loss: {avg_training_loss} | Valid Avg Loss: {avg_valid_loss} | Patience: {curr_patience} | LR: {scheduler.get_last_lr()} | Epoch Limit: {iter_limit}\")\n",
    "\n",
    "            if writer:\n",
    "              # log training and validation losses\n",
    "                writer.add_scalar(\"Training average loss\", avg_training_loss, itera)\n",
    "                writer.add_scalar(\"Validation average loss\", avg_valid_loss, itera)\n",
    "\n",
    "                # log GPU RAM usage\n",
    "                if torch.cuda.is_available():\n",
    "                    writer.add_scalar(\"GPU RAM Usage\", total_cuda_usage_iter / num_training_batches - base_cuda_usage, itera)\n",
    "\n",
    "              # log attack snippet and flush\n",
    "                writer.add_image(\"Attack Snippet\", mel_image(snippet.detach().to(\"cpu\")), itera, dataformats=\"HWC\")\n",
    "                writer.flush()\n",
    "            \n",
    "            # LR decay\n",
    "            scheduler.step()\n",
    "            \n",
    "            # refresh pbar to (hopefully) force update of progress bar\n",
    "            pbar.refresh()\n",
    "\n",
    "    except Exception as e:\n",
    "        # need to explicitly close pbar here so traceback can print error\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "            traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # close pbar to free stdout/stdsys (cant rmb which one)\n",
    "        if pbar is not None:\n",
    "            pbar.clear()\n",
    "            pbar.close()\n",
    "\n",
    "        # clear tensors from GPU memory to\n",
    "        # prevent memory leak\n",
    "        if attacked_data is not None:\n",
    "            attacked_data.to(\"cpu\")\n",
    "            del attacked_data\n",
    "            print(\"Cleared attacked data\")\n",
    "\n",
    "        if attack_stack is not None:\n",
    "            attack_stack.to(\"cpu\")\n",
    "            del attack_stack\n",
    "            print(\"Cleared attack stack\")\n",
    "\n",
    "        if mel is not None:\n",
    "            mel.to(\"cpu\")\n",
    "            del mel\n",
    "            print(\"Cleared mel\")\n",
    "\n",
    "        if logits is not None:\n",
    "            logits.to(\"cpu\")\n",
    "            del logits\n",
    "            print(\"Cleared logits\")\n",
    "        \n",
    "        if buffer is not None:\n",
    "            buffer.to(\"cpu\")\n",
    "            del buffer\n",
    "            print(\"Cleared buffer\")\n",
    "\n",
    "        loss.to(\"cpu\")\n",
    "        del loss\n",
    "        print(\"Cleared loss\")\n",
    "\n",
    "        # empty GPU cache and garbage collect\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print_cuda_usage()\n",
    "        \n",
    "        return best_snippet.detach().to(\"cpu\"), snippets, train_success, valid_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JML5ybTKPMEu",
    "outputId": "f3650f0c-d671-4acf-ae9f-40bc0e620d18",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29820775985717773 GB\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "jTU811FhsXQn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "PATIENCE = 5\n",
    "MIN_LIMIT = 45\n",
    "ITER_LIMIT = 30\n",
    "CLAMP_EP = 0.005\n",
    "PREPARE_METHOD = PrepareFront()\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "timestamp = datetime.datetime.now().strftime(f'%Y%m%d-%H%M%S_clamp_{CLAMP_EP}_{PREPARE_METHOD.name}')\n",
    "writer = SummaryWriter(log_dir=f\"../runs/clamp_tests/{timestamp}\", max_queue=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBzfVKNgHYp",
    "outputId": "80ab88a8-906c-4d44-a477-98b8717e3fc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare method: prepare_front\n",
      "Snippet initialised to [2.864544512704015e-07, 0.004999854601919651] of size (1, 10240)\n",
      "Clamp: 0.005\n",
      "Time Limit (Mins): 45\n",
      "Epochs Limit: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [02:47<?, ?it/s, Iter 2, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 2.230294942855835 | Valid Avg Loss: 0.8294642567634583 | Patience: 5 | LR: [0.001] | Epoch Limit: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [05:03<?, ?it/s, Iter 3, Training Batch 1/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.6505632400512695 | Valid Avg Loss: 5.791678428649902 | Patience: 4 | LR: [0.001] | Epoch Limit: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [07:16<?, ?it/s, Iter 4, Training Batch 3/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 1.2431236505508423 | Valid Avg Loss: 0.4689650535583496 | Patience: 5 | LR: [0.001] | Epoch Limit: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [09:13<?, ?it/s, Iter 5, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.6237580180168152 | Valid Avg Loss: 0.38854482769966125 | Patience: 5 | LR: [0.001] | Epoch Limit: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [11:36<?, ?it/s, Iter 6, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.7643721699714661 | Valid Avg Loss: 0.989629328250885 | Patience: 4 | LR: [0.001] | Epoch Limit: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [12:54<?, ?it/s, Iter 7, Training Batch 3/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.08130437135696411 | Valid Avg Loss: 0.07129406929016113 | Patience: 5 | LR: [0.0005] | Epoch Limit: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [14:07<?, ?it/s, Iter 8, Training Batch 3/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.03591983765363693 | Valid Avg Loss: 0.020416105166077614 | Patience: 5 | LR: [0.0005] | Epoch Limit: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [15:20<?, ?it/s, Iter 9, Training Batch 3/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.00945962406694889 | Valid Avg Loss: 0.028863122686743736 | Patience: 4 | LR: [0.0005] | Epoch Limit: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [17:08<?, ?it/s, Iter 10, Training Batch 3/500]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.6282690763473511 | Valid Avg Loss: 0.17250482738018036 | Patience: 3 | LR: [0.0005] | Epoch Limit: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [18:43<?, ?it/s, Iter 11, Training Batch 2/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.2832367420196533 | Valid Avg Loss: 0.1987932324409485 | Patience: 2 | LR: [0.0005] | Epoch Limit: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [19:59<?, ?it/s, Iter 12, Training Batch 3/500]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.03766603022813797 | Valid Avg Loss: 0.040420886129140854 | Patience: 1 | LR: [0.00025] | Epoch Limit: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% 0/1 [21:11<?, ?it/s, Patience expired! Terminating...] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trng Avg Loss: 0.01600782200694084 | Valid Avg Loss: 0.0315970778465271 | Patience: 0 | LR: [0.00025] | Epoch Limit: 18\n",
      "Cleared attacked data\n",
      "Cleared mel\n",
      "Cleared logits\n",
      "Cleared buffer\n",
      "Cleared loss\n",
      "0.3042306900024414 GB\n"
     ]
    }
   ],
   "source": [
    "best_snippet, snippets, train_success, valid_success = training_autograd_more(model, train_dataset, validation_dataset, \n",
    "                                                            PREPARE_METHOD,\n",
    "                                                            writer, lr=LR, \n",
    "                                                            iter_limit=ITER_LIMIT, mins_limit=MIN_LIMIT, patience=PATIENCE, clamp_epsilon=CLAMP_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "q59EbCsIfr-9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_mel(best_snippet.detach().to(\"cpu\").squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-kaeGzDCEUV"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "uYCZCjkitb0J",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clamp: 0.005\n",
      "Prepare Method: prepare_front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|| 250/250 [00:39<00:00,  6.31it/s, Valid Examples: 194 | Empty Sequences: 194 | Total SL = 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total valid examples: 194\n",
      "Success rate (Empty): 1.0\n",
      "Success rate (ASL): 0.0 (attacked) out of 122.16494845360825 (original)\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "# for now, metric is whether the transcription is empty or consists only of blank tokens\n",
    "\n",
    "def evaluate(snippet, prepare_method, model, test_dataset):\n",
    "    print(f\"Clamp: {CLAMP_EP}\\nPrepare Method: {prepare_method.name}\")\n",
    "    empty_counter = 0\n",
    "    char_counter = 0\n",
    "    total_examples = 0\n",
    "    original_chars = 0\n",
    "\n",
    "    snippet = snippet.to(device)\n",
    "    pbar = tqdm(range(len(test_dataset)), desc=\"Inference\")\n",
    "    test_dataset_iter = iter(test_dataset)\n",
    "    model.eval()\n",
    "\n",
    "    for i in pbar:\n",
    "        # evaluate if there are any words at all\n",
    "        example, answer = next(test_dataset_iter).values()\n",
    "        if isinstance(answer, tuple) or isinstance(answer, list):\n",
    "            answer = answer[0]\n",
    "        if answer != \"ignore_time_segment_in_scoring\":\n",
    "            attacked_example = prepare_method(snippet, example.to(device))\n",
    "            transcription = model.transcribe(attacked_example.squeeze(), language=\"en\", condition_on_previous_text=False, fp16=True)[\"text\"]\n",
    "\n",
    "            if not transcription.strip():\n",
    "                empty_counter += 1\n",
    "            char_counter += len(transcription.strip())\n",
    "            original_chars += len(answer)\n",
    "            total_examples += 1\n",
    "            pbar.set_postfix_str(f\"Valid Examples: {total_examples} | Empty Sequences: {empty_counter} | Total SL = {char_counter}\")\n",
    "\n",
    "        example.to(\"cpu\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"\\n\")\n",
    "    print(f\"Total valid examples: {total_examples}\")\n",
    "    print(f\"Success rate (Empty): {empty_counter/total_examples}\")\n",
    "    print(f\"Success rate (ASL): {char_counter/total_examples} (attacked) out of {original_chars/total_examples} (original)\")\n",
    "\n",
    "evaluate(best_snippet, PREPARE_METHOD, model, test_dataset) # commented to prevent the runtime from autorunning and crashing the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 10240])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets = torch.stack(list(map(lambda x: x.cpu(), snippets)) + [best_snippet.cpu()])\n",
    "snippets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(snippets.squeeze(), \"snippets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, train_success.values()))), \"train_success.pt\")\n",
    "torch.save(torch.tensor(list(train_success.keys())), \"train_ids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(list(map(torch.tensor, valid_success.values()))), \"valid_success.pt\")\n",
    "torch.save(torch.tensor(list(valid_success.keys())), \"valid_ids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hVIWKQO1V22"
   },
   "source": [
    "# Save and Hear Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise(random_snippet, ep):\n",
    "    # we assume torch.rand inits to [0, 1)\n",
    "    res = random_snippet * ep * 2 - ep\n",
    "    print(f\"Normalised, Min {torch.min(res)}, Max {torch.max(res)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD8MUV-y1Rsj"
   },
   "outputs": [],
   "source": [
    "# Save snippet to wav file\n",
    "save_audio(snippet, f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_snippet_only.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTI3OCNw5681"
   },
   "outputs": [],
   "source": [
    "save_audio(PREPARE_METHOD(snippet.to(\"cpu\"), tedlium_test[2][\"audio\"].unsqueeze(0)), f\"./snippets/clamp_{CLAMP_EP}_{PREPARE_METHOD.name}_combined.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
